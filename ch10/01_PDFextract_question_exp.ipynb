{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 벡터의 유사도 개념 파악하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 임베딩\n",
    "pip install openai  \n",
    "pip install pandas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "\n",
    "openai.api_key = 'API_key'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.016397610306739807, -0.021951215341687202, 0.015186872333288193, -0.02716265618801117, -0.03674328327178955, 0.011752059683203697, -0.034611329436302185, -0.006728152744472027, -0.02396472729742527, -0.016897698864340782, -0.008139584213495255, 0.010850585997104645, -0.01056764181703329, -0.022490784525871277, 0.011298032477498055, -0.005092998035252094, 0.01224556751549244, -0.002967625390738249, 0.008172485046088696, -0.016226528212428093, 0.001420479267835617, -0.014620983973145485, 0.01835848018527031, -0.012646953575313091, 0.0032719550654292107, 0.006300446577370167, 0.005336461588740349, -0.019042810425162315, -0.009198980405926704, -0.0017190512735396624, 0.034348126500844955, -0.016542373225092888, -4.070794602739625e-06, 0.0031781885772943497, 0.007244690787047148, -0.005639146082103252, -0.006543910130858421, 0.0033542062155902386, -0.0038361987099051476, -0.002403381746262312, -0.022411823272705078, -0.010251796804368496, 0.011271712370216846, -0.024833299219608307, 0.01315362099558115, 0.009080538526177406, -0.010376818478107452, -0.025701873004436493, -0.0199903454631567, 0.016516052186489105, 0.014607823453843594, -0.016134407371282578, -0.007850060239434242, -0.01772679202258587, 0.0007159971864894032, 0.027136335149407387, -0.009593786671757698, -0.0006682914681732655, 0.0043790568597614765, -0.014041935093700886, 0.004714642185717821, 0.020332511514425278, -0.013660289347171783, 0.011857341043651104, -0.010245217010378838, 0.00794876180589199, 0.0220696572214365, 0.002919919556006789, -0.02374100312590599, 0.006224775221198797, 0.017779432237148285, 0.041823118925094604, -0.020674675703048706, -0.008902876637876034, 0.03195296972990036, -0.006738022901117802, -0.009784610010683537, 0.0003471003146842122, -0.03168976306915283, 0.014081415720283985, 0.03105807490646839, -0.02237234264612198, 0.001457492238841951, 0.009692488238215446, 0.008988417685031891, 0.011877081356942654, -0.03287418186664581, 0.015186872333288193, -0.034321803599596024, -0.005912220571190119, 0.005372652318328619, 0.0241884496062994, -0.010811105370521545, 0.03608527034521103, 0.005635856185108423, 0.008856815285980701, -0.012015263549983501, 0.03447972610592842, -0.008475169539451599, -0.018332161009311676, 0.0012798295356333256, -0.005129188299179077, -0.019713981077075005, -0.009383223950862885, -0.03068958967924118, -0.004971266258507967, 0.019648181274533272, 0.008310667239129543, 0.009389803744852543, -0.0152131924405694, 0.014542022719979286, 0.025767674669623375, 0.017805753275752068, -0.03874363377690315, -0.019648181274533272, 0.013107560575008392, -0.0037934279534965754, -0.0158712025731802, -0.008442268706858158, -0.010593961924314499, -0.002049701288342476, 0.014647304080426693, 0.003309790510684252, 0.009310842491686344, 0.008475169539451599, 0.006175424437969923, -0.023240914568305016, -0.032821543514728546, 0.022543424740433693, 0.014634143561124802, 0.053114570677280426, 0.01795051433146, 0.029584132134914398, -0.01215344574302435, -0.03466397151350975, -0.017845232039690018, -0.015884362161159515, -0.00027780362870544195, -0.020319350063800812, -0.025175465270876884, 0.008863396011292934, 0.023161955177783966, -0.011975782923400402, -0.03384803608059883, 0.021635370329022408, 0.022793468087911606, 0.04569222033023834, 0.005951701197773218, -0.008843655698001385, -6.019763895892538e-05, 0.00022475156583823264, -0.013094400055706501, 0.017305664718151093, -0.00400399137288332, 0.0013686609454452991, 0.011416474357247353, -0.01488418783992529, 0.020345671102404594, -0.0009401318966411054, -0.006050402764230967, 0.013252322562038898, 0.026662567630410194, 0.02043779194355011, -0.02789962664246559, 0.004576459992676973, 0.04140199348330498, -0.00355325429700315, -0.012179765850305557, -0.016094926744699478, -0.015739601105451584, 0.0041783638298511505, 0.012502191588282585, -0.011284872889518738, 0.016187047585844994, -0.023609401658177376, 0.01430513896048069, 0.020042985677719116, -0.0001239937701029703, -0.014607823453843594, 0.00396780064329505, -0.03300578519701958, -0.01103482861071825, 0.011311192996799946, 0.007185469847172499, 0.012100805528461933, -0.008106684312224388, 0.010449199937283993, -0.01652921363711357, 0.01642393134534359, -0.007685557473450899, 0.01380505133420229, 0.030163181945681572, -0.005191699601709843, -0.011041409336030483, -0.6190558671951294, -0.012771975249052048, 0.023767324164509773, -0.004688321612775326, 0.028478676453232765, 0.019148092716932297, -0.0010240281699225307, 0.025807155296206474, 0.005366072058677673, 0.012219246476888657, -0.012238986790180206, 0.019569220021367073, 0.0011942882556468248, 0.013581328094005585, 0.014370939694344997, -0.012107385322451591, 0.032084569334983826, -0.005152218975126743, 0.012890417128801346, -0.013778730295598507, -0.03200560808181763, 0.007600016426295042, -0.01534479483962059, 0.01426565833389759, 0.030163181945681572, 0.015028949826955795, 0.011903402395546436, -0.005981311667710543, -0.019253375008702278, 0.05306193232536316, -0.012857516296207905, 0.03637479618191719, -0.009580626152455807, 0.002378706354647875, 0.041191428899765015, -0.017845232039690018, -0.009152919985353947, 0.02779434435069561, 0.021503768861293793, 0.037769779562950134, -0.012396909296512604, -0.020793117582798004, 0.004267195239663124, -0.006652481853961945, 0.001364548341371119, 0.009725389070808887, 0.0199508648365736, -0.008698892779648304, -0.001215673633851111, 0.001212383504025638, -0.018845409154891968, -0.0023359358310699463, -0.005366072058677673, 0.017516227439045906, -0.003750657429918647, 0.011350673623383045, 0.010699243284761906, -0.02585979551076889, 5.5416785471607e-05, -0.002220784081146121, 0.014489381574094296, 0.0032308294903486967, -0.020371992141008377, -0.0012576216831803322, -0.03195296972990036, 0.01768731139600277, -0.034321803599596024, 0.00712624890729785, -0.010317597538232803, -0.02685997076332569, -0.009317422285676003, -0.027952266857028008, -0.0071065085940063, 0.015858042985200882, 0.03619055449962616, 0.002192818559706211, 0.0252281054854393, 0.003199573839083314, -0.012627213262021542, -0.008685733191668987, 0.0056983670219779015, 0.014055094681680202, -0.011403314769268036, -0.009870151057839394, 0.0006983131752349436, -0.0027718674391508102, -0.030505346134305, -0.009205561131238937, -0.003609185107052326, -0.04153359681367874, 0.018977010622620583, 0.033347949385643005, 0.004622520878911018, -0.01276539545506239, -0.00895551685243845, -0.005320011172443628, 0.0027422569692134857, -0.02058255486190319, 0.017147742211818695, -0.0063465069979429245, -0.004819923546165228, -0.004596200305968523, 0.011337513104081154, -0.0049416557885706425, 0.04603438451886177, -0.0013933363370597363, -0.0338217169046402, -0.022648707032203674, 0.0007600015960633755, -0.007764518726617098, 0.027636421844363213, 0.005783908534795046, 0.0006843304727226496, -0.00331143569201231, 0.03663799911737442, -0.021306365728378296, 6.163703801576048e-05, -0.011140109971165657, 0.009639847092330456, -0.00802772305905819, 0.016173887997865677, -0.01430513896048069, 0.01862168498337269, -0.013087820261716843, -0.01630548946559429, 0.04108614847064018, -0.0043198359198868275, -0.01003465335816145, -0.021056322380900383, 0.010738723911345005, -0.019253375008702278, -0.009245041757822037, 0.013778730295598507, -0.016963498666882515, 0.007540795486420393, -0.002437927294522524, 0.026070358231663704, -0.0003816458338405937, 0.021609051153063774, -0.02593875676393509, -0.024464813992381096, 0.013936652801930904, -0.03503245487809181, -0.003878969233483076, 0.014186697080731392, -0.0035828647669404745, -0.03168976306915283, -0.01660817489027977, -0.0008114086813293397, 0.022267060354351997, 0.01215344574302435, 0.0040368917398154736, -0.0015405660960823298, 0.009712228551506996, 0.01931917481124401, 0.005596375558525324, 0.02296455204486847, -0.004721222445368767, -0.030557988211512566, 0.011587557382881641, 0.0094358641654253, -0.007869800552725792, -0.01207448448985815, -0.006724862847477198, 0.009791189804673195, -0.05056149512529373, -0.011225651949644089, 0.013791890814900398, -0.01921389438211918, -0.026702048256993294, -0.003908579703420401, 0.0044119576923549175, 0.01166651863604784, -0.02493858151137829, 0.0002708122774492949, 0.001281474600546062, 0.020964201539754868, -0.008060622960329056, -0.018792767077684402, -0.02545182965695858, 0.0006781616248190403, 0.013324704021215439, -0.014055094681680202, 0.0110545689240098, 0.04121775180101395, 0.012489031068980694, 0.006728152744472027, 0.032821543514728546, -0.027320578694343567, 0.010264957323670387, -0.009468764998018742, 0.022569745779037476, -0.010409719310700893, 0.0005313431029208004, -0.01058738213032484, -0.016950339078903198, -0.010962448082864285, 0.03313738852739334, 0.02585979551076889, 0.023898925632238388, 0.007981661707162857, 0.0030844220891594887, 0.015397435054183006, -0.00852781068533659, 0.016660815104842186, -0.03742761164903641, -0.007751358672976494, -0.014134055934846401, 0.011370413936674595, 0.011561237275600433, -0.007652657106518745, -0.023662041872739792, -0.006172134540975094, -0.003089357167482376, 0.030084220692515373, 0.011936302296817303, -0.02029303088784218, 0.00999517273157835, -0.02184593491256237, 0.014463061466813087, -0.0017404366517439485, 0.013028599321842194, -0.0013859337195754051, -0.015331634320318699, -0.009935951791703701, 0.005323301535099745, 0.00342823239043355, 0.027662742882966995, 0.015660639852285385, -0.011580977588891983, -0.025925597175955772, 0.009093699045479298, -0.01858220435678959, 0.041928403079509735, 0.014963149093091488, -0.025543950498104095, 0.004115852992981672, -0.017081940546631813, 0.017226703464984894, 0.004951525945216417, -0.005211439915001392, 0.0031502232886850834, 0.005764168221503496, -0.0099754324182868, 0.009876730851829052, 0.029373569414019585, 0.005204859655350447, 0.0051423488184809685, -0.0399017296731472, 0.01114669069647789, -0.03763817623257637, -0.0063201868906617165, -0.00604711240157485, -0.002023380948230624, -0.0004383992054499686, -0.03837514668703079, 0.00040673246257938445, 0.011100629344582558, 0.01656869426369667, 0.01927969418466091, 0.008133004419505596, 0.03476925194263458, -0.014476221054792404, 0.016713455319404602, 0.02392524667084217, -0.018792767077684402, -0.0015923843020573258, -0.029821015894412994, -0.030031578615307808, 0.0012378814863041043, -0.008067203685641289, -0.03700648620724678, 0.004260614980012178, -0.022898750379681587, 0.0016664104769006371, -0.013594487681984901, 0.01601596549153328, -0.01795051433146, 0.021859094500541687, -0.02378048375248909, -0.0036684060469269753, -0.040033333003520966, 0.008284347131848335, 0.019200732931494713, 0.00902789831161499, -0.02995261736214161, -0.029531491920351982, 0.006438628304749727, -0.03319002687931061, 0.03229513391852379, -0.008725213818252087, 0.013272062875330448, -0.01008729450404644, 0.01118617132306099, -0.04711351916193962, -0.025399187579751015, 0.028136510401964188, 0.004434987902641296, 0.010876906104385853, -0.024122649803757668, 0.0017716920701786876, -0.013239162042737007, -0.0035828647669404745, -0.014015614055097103, 0.012232406996190548, 0.0033476261887699366, -0.0014393969904631376, -0.005086417775601149, 0.010179415345191956, -0.01720038242638111, -0.01850324310362339, -0.005711527541279793, -0.018713805824518204, -0.019898224622011185, -0.020108787342905998, -0.009113439358770847, -0.01116643100976944, -0.0315055213868618, 0.024214770644903183, 0.01697666011750698, -0.00854755099862814, 0.015410595573484898, -0.011929722502827644, -0.0016409126110374928, 0.05595717579126358, -0.03276890143752098, 0.016766095533967018, -0.013291803188621998, 0.015094750560820103, 0.015055269934237003, -0.025175465270876884, -0.007718457840383053, 0.0036519558634608984, -0.0029182746075093746, 0.022951390594244003, -0.0052969809621572495, 0.013660289347171783, 0.005622696131467819, 0.013397084549069405, 0.0007435513543896377, -0.011798120103776455, -0.03661167994141579, 0.033453233540058136, -0.019713981077075005, -0.011363834142684937, -0.010613702237606049, 0.0152131924405694, 0.024030527099967003, 0.008277766406536102, 0.012561412528157234, 0.015002629719674587, -0.00023523859272245318, 0.04124407097697258, -0.014568342827260494, -0.007343392353504896, -0.009060798212885857, -0.009212140925228596, -0.009297681972384453, 0.007020967546850443, 0.03326898813247681, 0.005053517408668995, 0.0006123605999164283, -0.0008587031625211239, 0.029347248375415802, 0.015331634320318699, 0.02151692844927311, 0.014792066067457199, -0.005537154618650675, 0.0010799589799717069, -0.015489556826651096, 0.00042482774006202817, 0.011416474357247353, -0.010784785263240337, -0.013936652801930904, 0.048061054199934006, 0.009245041757822037, -0.02675468847155571, -0.004247454926371574, 0.021372167393565178, -0.002331000752747059, 0.007224950473755598, 0.017924193292856216, 0.010771624743938446, 0.0008611706434749067, 0.007613176479935646, -0.018345320597290993, 0.003155158367007971, -0.01066634338349104, -0.018490083515644073, -0.014647304080426693, -0.03540094196796417, -0.008501489646732807, -0.022490784525871277, -0.009856990538537502, -0.025030702352523804, -0.00854755099862814, -0.031084395945072174, -0.041849441826343536, -0.005948410835117102, 0.010422879830002785, 0.03205825015902519, -0.02388576604425907, -0.01817423850297928, 0.0047541228123009205, -0.005704947281628847, -0.023477798327803612, 0.012521931901574135, 0.0014287043595686555, -0.014147216454148293, 0.026886291801929474, 0.009363483637571335, -0.019384976476430893, 0.0007020144839771092, -0.008514650166034698, 0.023240914568305016, 0.013469466008245945, 0.012383749708533287, -0.004777153022587299, -0.0008319714688695967, 0.0006477286806330085, 0.003622345393523574, 0.009949112311005592, -0.007560535799711943, 0.013166781514883041, 0.02021406963467598, -0.02868923917412758, 0.003276890143752098, -0.024056848138570786, 0.006149103865027428, 0.013456305488944054, 0.0142524978145957, 0.009179240092635155, -0.020714156329631805, 0.016187047585844994, 0.0231093131005764, -0.010357078164815903, 0.006764343474060297, -0.019885065034031868, 0.029215646907687187, 0.025070182979106903, -0.018490083515644073, 0.014739425852894783, -0.014370939694344997, 0.015357955358922482, -0.011001928709447384, -0.019898224622011185, 0.029031403362751007, 0.03187400847673416, -0.0044119576923549175, 0.0048955949023365974, -0.013252322562038898, -0.024214770644903183, -0.02325407601892948, -0.011409894563257694, 0.0012082710163667798, 0.015068430453538895, -0.022017017006874084, -0.014278818853199482, -0.007264431100338697, -0.007836899720132351, 0.0006189407431520522, 5.145844261278398e-05, 7.77788445702754e-05, -0.03276890143752098, -0.015989644452929497, 0.003314725589007139, -0.00960694719105959, -0.009166080504655838, -0.009310842491686344, -0.02463589608669281, -0.014528862200677395, -0.008593611419200897, -0.007468414027243853, 0.016884537413716316, 0.007902700453996658, 0.00683672446757555, 0.003107452532276511, 0.0008138762204907835, 0.005366072058677673, -0.026425683870911598, -0.004852824378758669, 0.013910332694649696, 0.05316721275448799, 0.01642393134534359, 0.02600455842912197, 0.018305839970707893, 0.020187748596072197, 0.010936127044260502, 0.0023688361980021, -0.007040707860141993, -0.021674850955605507, 0.007698717527091503, -0.032084569334983826, 0.02649148553609848, -0.00020727317314594984, 0.021424807608127594, 0.03648007661104202, 0.027768025174736977, 0.0019542898517102003, 0.032163530588150024, -0.006619581021368504, -0.004948235582560301, -0.02545182965695858, 0.012337688356637955, 0.006326766684651375, -0.025833474472165108, 0.00999517273157835, -0.02608351968228817, 0.011350673623383045, -0.018226878717541695, 0.0073828729800879955, -0.02029303088784218, 0.016555532813072205, -0.017108261585235596, 0.03250569850206375, -0.054746437817811966, 0.004648840986192226, 0.02512282505631447, 0.010995347984135151, 0.002334290649741888, -0.018305839970707893, 0.011824441142380238, -0.013502366840839386, 0.00662287138402462, 0.02608351968228817, 0.007303911726921797, -0.022017017006874084, 0.00013921025674790144, -0.0044382777996361256, 0.020003505051136017, -0.02689945138990879, -0.018490083515644073, 0.010074133984744549, -0.015002629719674587, -0.018226878717541695, -0.015910683199763298, -0.028899801895022392, -0.04548165574669838, 0.017713630571961403, 0.0029116945806890726, -0.015950163826346397, 0.02341199852526188, 0.007514474913477898, -0.01831899955868721, -0.010291277430951595, 0.030110539868474007, 0.0035269339568912983, 0.011758639477193356, 0.04087558388710022, 0.0284260343760252, -0.0035927349235862494, -0.021793292835354805, 0.013212841935455799, 0.009942532517015934, -0.014041935093700886, -0.01376557070761919, 0.026873130351305008, -0.012541672214865685, -0.020319350063800812, 0.0008118199184536934, -0.0004141350800637156, 0.004560009576380253, 0.0011819505598396063, 0.03300578519701958, -0.006659061647951603, 0.0013768860371783376, 0.010212316177785397, -0.005823389161378145, -0.014976308681070805, 0.041559915989637375, -0.008350147865712643, -0.0013694834196940064, -0.012160025537014008, -0.03666432201862335, -0.005678626708686352, -0.006626161281019449, -0.010139934718608856, 0.028189150616526604, 0.022174939513206482, -0.02072731778025627, -0.004283645655959845, -0.0002632040122989565, -0.007586855906993151, 0.010172835551202297, -0.014397259801626205, 0.03276890143752098, -0.005668756552040577, 0.003757237456738949, 0.005922090727835894, 0.0051555088721215725, 0.003888839390128851, 0.005632566288113594, 0.002518533496186137, 0.037322331219911575, -0.004964685998857021, 0.009751709178090096, -0.007159149274230003, 0.03900683671236038, 0.013752410188317299, 0.0017124712467193604, -0.005438453052192926, -0.006441918667405844, -0.0023737712763249874, -0.009883311577141285, -0.009870151057839394, -0.005892480257898569, -0.0199508648365736, -0.006784083787351847, -0.03734865039587021, 0.00042236020090058446, -0.026175640523433685, 0.01118617132306099, 0.012337688356637955, 0.04058606177568436, -0.011870501562952995, -0.01921389438211918, -0.01376557070761919, 0.02545182965695858, -0.014160376973450184, -0.024017367511987686, -0.0017651120433583856, 0.0029692703392356634, -0.014555182307958603, 0.013949813321232796, -0.009001577273011208, 0.009778029285371304, -0.011975782923400402, 0.007534215226769447, 0.013212841935455799, -0.0068893651477992535, 0.019371816888451576, -0.008185645565390587, -0.00015380985860247165, -0.017042459920048714, -0.01157439686357975, -0.0005876852665096521, 0.01116643100976944, -0.0006551312981173396, 0.017818912863731384, 0.008040882647037506, 0.0131338806822896, -0.019871903583407402, -0.010199155658483505, -0.005987891461700201, 0.014739425852894783, 0.026702048256993294, 0.028636597096920013, -0.02489910088479519, -0.036690641194581985, -0.002199398586526513, -0.006300446577370167, -0.01627916842699051, -0.03661167994141579, -0.014147216454148293, 0.0007772743701934814, 0.020279869437217712, -0.002344160806387663, -0.02716265618801117, 0.021424807608127594, -0.017582029104232788, -0.02805754914879799, 0.005635856185108423, 0.009639847092330456, 0.004533689469099045, 0.00301368604414165, 0.033716436475515366, -0.0035335139837116003, 0.004277065396308899, -0.010245217010378838, 0.005329881329089403, -0.003135418053716421, -0.016871377825737, -0.00035409166594035923, 0.006770923733711243, -0.027188975363969803, 0.03363747522234917, 0.006135943811386824, -0.024609576910734177, -0.020003505051136017, 0.008369888179004192, -0.029557812958955765, 0.0014402195811271667, 0.017345145344734192, 0.015436915680766106, 0.005037066992372274, -0.005329881329089403, 0.006020792294293642, 0.02660992741584778, -0.008442268706858158, 0.006576810497790575, -0.006849884986877441, -0.02178013324737549, -0.005625986028462648, -0.007672397419810295, -0.0039645107463002205, -0.02797858789563179, -0.02221442013978958, -0.012896996922791004, 0.01324574276804924, -0.0018572333501651883, 0.0189901702105999, 0.003934900276362896, 0.008113264106214046, -0.00342823239043355, 0.0008101749117486179, -0.0014245917554944754, -0.00026217589038424194, -0.00899499747902155, 0.040849264711141586, -0.026820490136742592, -0.019924545660614967, 0.011238811537623405, 0.012337688356637955, -0.012173186056315899, -0.0137129295617342, 0.03726968914270401, -0.01809527724981308, -0.0010602186666801572, 0.0022388792131096125, -0.0018868438201025128, 0.007455253973603249, -0.022135458886623383, 0.0022668447345495224, -0.0020348960533738136, -0.005639146082103252, 0.021727493032813072, 0.007790839299559593, -0.0158317219465971, -0.016410771757364273, 0.0027965428307652473, -0.01854272373020649, 0.021674850955605507, -0.005487803835421801, -0.01809527724981308, 0.011673098430037498, -0.00304165156558156, 0.03287418186664581, -0.029031403362751007, -0.015278994105756283, -0.0005416245548985898, -0.006310316734015942, -0.033979639410972595, 0.04685031622648239, 0.01530531421303749, -0.0069485860876739025, -0.016739776358008385, -0.012403490021824837, 0.004645551089197397, -0.002372126327827573, -0.024517454206943512, 0.01735830493271351, -0.015318474732339382, -0.015068430453538895, 0.036058951169252396, -0.014186697080731392, -0.025662392377853394, -0.011271712370216846, 0.003421652363613248, 0.0011515176156535745, 0.015318474732339382, 0.2636251449584961, -0.019700821489095688, -0.006241225637495518, 0.021240564063191414, 0.012311368249356747, 0.004184944089502096, 0.0025645941495895386, -0.0032571498304605484, 0.015121071599423885, 0.0006839192355982959, 0.0038690990768373013, 0.0012913447571918368, -0.011376993730664253, 0.0026764560025185347, -0.00421784445643425, -0.027399539947509766, -0.020648356527090073, 0.005843129474669695, 0.0014509122120216489, -0.02504386380314827, 0.00784347951412201, 0.0017799172783270478, -0.01905597187578678, 0.014476221054792404, -0.008869975805282593, 0.0022569745779037476, -0.011225651949644089, 0.0019822553731501102, -0.005879319738596678, 5.952934952802025e-05, -0.008718633092939854, -0.014818387106060982, 0.007830319926142693, 0.010600541718304157, -0.0031403531320393085, 0.02084575966000557, 0.030479026958346367, -0.02429373189806938, 0.028110189363360405, 0.028557637706398964, -0.008797594346106052, 0.028715558350086212, 0.0036519558634608984, 0.004938365425914526, -0.037690818309783936, 0.016042284667491913, -0.013568167574703693, -0.020687837153673172, -0.00658668065443635, 0.04924547299742699, -0.028820840641856194, -0.009251621551811695, 0.009731968864798546, 0.042375847697257996, -0.010501841083168983, -0.0035104837734252214, 0.013897172175347805, -0.006040532607585192, -0.009738548658788204, 0.005872739944607019, 0.011817860417068005, 0.041928403079509735, -0.03205825015902519, 0.010383399203419685, -0.008968677371740341, -0.0004630745970644057, -0.021938055753707886, 0.011100629344582558, 0.016805576160550117, -0.025057023391127586, 0.0019608698785305023, -0.007435513660311699, -0.000606191752012819, 0.01927969418466091, -0.05371994152665138, -0.025504469871520996, 0.030373744666576385, -0.013581328094005585, 0.036401115357875824, 0.02449113503098488, -0.016068605706095695, 0.011442795395851135, 0.015660639852285385, -0.002178013324737549, -0.005708237178623676, -0.02467537671327591, 0.015410595573484898, 0.002740612020716071, -0.011692838743329048, -0.013258902356028557, 0.02363572083413601, -0.024701697751879692, 0.0011737254681065679, -0.004869274329394102, 0.009416123852133751, -0.00531343137845397, -0.03590102866292, 0.02471485733985901, -0.019792942330241203, 0.010238636285066605, -0.014726265333592892, -0.02961045317351818, 0.018042635172605515, 0.015410595573484898, -0.0009796124650165439, -0.008613351732492447, -0.010100454092025757, 0.016634494066238403, -0.00945560447871685, -0.030215822160243988, -0.02496490254998207, 0.001142469933256507, 0.01917441375553608, 0.015805400907993317, 0.0022257191594690084, 0.0009269716683775187, 0.031163357198238373, -0.0007739843567833304, 0.010488680563867092, -0.0003884315665345639, -0.006415598094463348, -0.01742410659790039, 0.00583325931802392, 0.0034742930438369513, 0.007409193553030491, -0.011291452683508396, -0.03013686090707779, 0.01805579662322998, -0.003954640589654446, -0.028768200427293777, -0.0022076237946748734, -0.001084071584045887, 0.0401386134326458, -0.022503944113850594, -0.021372167393565178, 0.03563782572746277, -0.005872739944607019, 0.014857866801321507, -0.004951525945216417, 0.016134407371282578, 0.0018572333501651883, 0.0012337688822299242, 0.004372477065771818, 0.018595363944768906, -0.016950339078903198, -0.03213721141219139, 0.03103175386786461, -0.010797944851219654, 0.0035795746371150017, -0.008685733191668987, -0.03329531103372574, 0.0016680555418133736, 0.0013744184980168939, 0.006744603160768747, 0.045613259077072144, 0.01107430923730135, -0.03661167994141579, -0.032347775995731354, -0.010028073564171791, 0.0015126006910577416, -0.032163530588150024, -0.0017651120433583856, 0.05332513526082039, -0.026596765965223312, -0.014476221054792404, -0.021016841754317284, -0.16739776730537415, 0.015818562358617783, 0.012192926369607449, -0.005938540678471327, 0.0027965428307652473, 0.019450778141617775, 0.016371291130781174, 0.008231705985963345, 0.006942006293684244, 0.003471003146842122, 0.015621159225702286, -0.0016532503068447113, -0.019069131463766098, 0.005448323208838701, -0.007507894653826952, -0.015555357560515404, -0.017305664718151093, -0.005116028245538473, 0.015173711813986301, 0.0030301364604383707, -0.006267545744776726, -0.006425468251109123, 0.022385502234101295, -0.004833084065467119, 0.007093348540365696, 0.03303210437297821, -0.013541847467422485, 0.02512282505631447, -0.019332336261868477, -0.009416123852133751, -0.03024214319884777, 0.012015263549983501, 0.02345147915184498, -0.016147566959261894, 0.03698016703128815, 0.009429284371435642, -0.019858743995428085, -0.0012107385555282235, -0.01322600245475769, 0.010936127044260502, 0.002171433297917247, 0.020003505051136017, 0.004096112679690123, -0.008738373406231403, -0.009646427817642689, 0.010462360456585884, 0.005218019708991051, 0.013199682347476482, 0.016292329877614975, -0.023991046473383904, 0.003209443995729089, -0.0263467226177454, 0.010482100769877434, 0.015673799440264702, 0.00392832001671195, 0.0252281054854393, 0.017595188692212105, 0.014107735827565193, -0.008185645565390587, 0.007389453239738941, -0.03211089223623276, -0.009126599878072739, 0.026241442188620567, 0.0033723015803843737, 0.0012164961080998182, -0.0036585358902812004, -0.02184593491256237, 0.01274565514177084, -0.025662392377853394, -0.009949112311005592, 0.016660815104842186, -0.005935250781476498, 0.006928845774382353, -0.02392524667084217, -0.012864097021520138, 0.0033065006136894226, -0.029399890452623367, -0.00013232171477284282, 0.00380329811014235, 0.0028014779090881348, -0.005089707672595978, 0.015884362161159515, -0.030452705919742584, 0.00794876180589199, 0.02121424488723278, 0.011988943442702293, 0.00956746656447649, -0.01760835014283657, 0.0030301364604383707, -0.009383223950862885, 0.03963852673768997, -0.02247762307524681, -0.018555883318185806, 0.004777153022587299, 0.013752410188317299, 0.029926298186182976, -0.01876644790172577, 0.01723986305296421, -0.0014073189813643694, -0.001992125529795885, 0.006415598094463348, -0.006915685720741749, -0.03690120577812195, 0.025478148832917213, 0.03321634978055954, 0.023951565846800804, 0.01801631599664688, 0.015989644452929497, 0.04624494910240173, -0.007718457840383053, 0.002411606954410672, -0.0008842010283842683, 0.022227579727768898, 0.008764694444835186, 0.03934900090098381, 0.035769425332546234, -0.012923317961394787, -0.0141735365614295, 0.01623968780040741, -0.004286935552954674, 0.04527109116315842, -0.012864097021520138, -0.004727802239358425, 0.017029300332069397, 0.00708676828071475, 0.0032324744388461113, -0.05422002822160721, -0.028583956882357597, 0.018713805824518204, 0.017555708065629005, 9.993527783080935e-05, -0.008422528393566608, 0.009679327718913555, 0.021859094500541687, -0.027583781629800797, -0.016147566959261894, -0.007363132666796446, -0.022793468087911606, -0.0028442484326660633, -0.0061326539143919945, 0.027031052857637405, -0.01434461958706379, -0.01162703800946474, -0.009810930117964745, -0.006974906660616398, 0.002989010652527213, -0.0016425576759502292, 0.01166651863604784, 0.001302037388086319, -0.009093699045479298, -0.004280355293303728, 0.0031304829753935337, 0.0008031835313886404, 0.030663268640637398, 0.015357955358922482, -0.0026172350626438856, -0.009291102178394794, -0.01772679202258587, 0.013857691548764706, -0.019253375008702278, 0.0007016032468527555, -0.037138089537620544, -0.03421652317047119, 0.0009746773866936564, 0.017042459920048714, -0.01627916842699051, 0.01858220435678959, 0.02025355026125908, -0.006142524071037769, -0.005905640311539173, -0.013397084549069405, -0.0036420857068151236, 0.008889716118574142, 0.01950341835618019, -0.0013242452405393124, -0.008067203685641289, -0.005866159684956074, -0.038059301674366, -0.04537637531757355, -0.0028343782760202885, 0.03987541049718857, -0.01842428185045719, 0.02367520146071911, 0.037848737090826035, -0.014449900947511196, -0.002957755234092474, -0.024214770644903183, 0.02174065262079239, -0.013541847467422485, -0.004921915475279093, 0.006389277521520853, 0.012127125635743141, -0.021372167393565178, -0.0209905207157135, 0.017371466383337975, -0.0040368917398154736, 0.012561412528157234, 0.0189112089574337, -0.022451303899288177, 0.03337427228689194, -0.04290225729346275, -0.010455779731273651, -0.02009562775492668, -0.008231705985963345, 0.01858220435678959, -0.026688888669013977, -0.023569921031594276, -0.016713455319404602, -0.016884537413716316, -0.014647304080426693, 0.0073565524071455, 0.021056322380900383, 0.0147525854408741, 0.008856815285980701, 0.002319485414773226, 0.004086242523044348, -0.006251095794141293, 1.740128209348768e-05, 0.01801631599664688, -0.04463940113782883, -0.011350673623383045, 0.012850936502218246, -0.021345846354961395, 0.007415773347020149, 0.020608875900506973, 0.007521055173128843, -0.014068255200982094, -0.02761010266840458, -0.060589566826820374, 0.008823915384709835, -0.001437752041965723, -0.02905772440135479, 0.012344269081950188, -0.011449375189840794, 0.0034413926769047976, -0.021451128646731377, -0.021227404475212097, -0.012646953575313091, 0.0017305664950981736, 0.01014651544392109, -0.003816458396613598, -0.023017192259430885, -0.022832948714494705, -0.03979644924402237, 0.02685997076332569, 0.0068564647808671, 0.012969378381967545, 0.012410069815814495, -0.026175640523433685, 0.011988943442702293, -0.0035598345566540956, -0.0038263285532593727, -0.02895244210958481, -0.016410771757364273, -0.026280922815203667, 0.010271537117660046, -0.01705562137067318, -0.005579925142228603, -0.008165905252099037, -0.023977886885404587, 0.014699945226311684, 0.005737847648561001, -0.010449199937283993, -0.013528686948120594, -0.0011539851548150182, -0.006757763214409351, 0.01742410659790039, 0.015450076200067997, -0.0035236438270658255, -0.019424457103013992, 0.029478851705789566, -0.013416824862360954, -0.015607998706400394, 0.01116643100976944, 0.003628925420343876, 0.004662001505494118, 0.018740126863121986, -0.008448849432170391, 0.001163855311460793, 0.037322331219911575, 0.03771713748574257, -0.007001227233558893, -0.013581328094005585, -0.037875059992074966, 0.022280219942331314, 0.024122649803757668, 0.022582905367016792, -0.0009680973016656935, 0.006053692661225796, 0.0008710408001206815, 0.001898359041661024, -0.01376557070761919, -0.006428758148103952, 0.0038855494931340218, -0.00895551685243845, -0.00423429487273097, 0.007014387287199497, -0.05490436032414436, -0.025504469871520996, 0.007619756739586592, 0.018213719129562378, -0.00020819850033149123, 0.00712624890729785, 0.01616072654724121, 0.0018177528399974108, -0.01850324310362339, -0.009758288972079754, 0.030479026958346367, -0.006517589557915926, 0.007527634967118502, -0.02139848656952381, -0.009376643225550652, 0.007034127600491047, 0.012002103962004185, 0.004777153022587299, 0.005622696131467819, 0.0120547441765666, 0.01319310162216425, -0.06190558522939682, 0.0008373177843168378, 0.021319525316357613, 0.008330407552421093, 0.013791890814900398, 0.029584132134914398, 0.013555007055401802, -0.0036453758366405964, 0.0052278898656368256, 0.022095978260040283, -0.0032439895439893007, -0.0018259779317304492, -0.01004781387746334, -0.020056147128343582, -0.0043066758662462234, 0.008462009020149708, 0.010705824010074139, -0.022832948714494705, 0.006770923733711243, -0.0008661057217977941, 0.01939813606441021, 0.007830319926142693, -0.028215471655130386, 0.023833123967051506, -0.006033952347934246, -0.007428933400660753, -0.0095148254185915, -0.01697666011750698, -0.029636774212121964, 0.02816283144056797, 0.016950339078903198, 0.013041759841144085, 0.015134231187403202, -0.03184768557548523, 0.02259606495499611, 0.01620020717382431, -0.0038493587635457516, -0.002806412987411022, 0.0005473821074701846, 0.016924018040299416, 0.0003292106557637453, -0.014634143561124802, -0.025293907150626183, -0.015200032852590084, -0.030979113653302193, 0.02378048375248909, -0.002653425559401512, 0.027662742882966995, -0.0263467226177454, 0.06185294687747955, 0.0017585319001227617, -0.0063333469443023205, 0.003301565535366535, 0.001901649055071175, -0.006412308197468519, 0.021240564063191414, -0.009356902912259102, 0.014949988573789597, -0.0169108584523201, 0.025214945897459984, -0.006303736474364996, 0.0032308294903486967, -0.047166161239147186, -0.012403490021824837, -0.006764343474060297, -0.00579706858843565, 0.023912085220217705, -0.052403923124074936, 0.01631864905357361, 0.017595188692212105, 0.0104755200445652, 0.002923209685832262, 0.009922792203724384, -0.001223076251335442, -0.006764343474060297, 0.0037605275865644217, -0.0005572522641159594, 0.007678977679461241, -0.025688713416457176, -0.01322600245475769, -0.010982188396155834, -0.033900678157806396, 0.0014229468069970608, 0.008014562539756298, -0.017858393490314484, -0.01664765551686287, 0.005004166625440121, 0.016963498666882515, 0.017226703464984894, 0.01947709731757641, 0.013936652801930904, -0.02259606495499611, 0.026017718017101288, 0.04737672582268715, -0.023359356448054314, -0.007586855906993151, 0.00291662965901196, 0.013429985381662846]\n"
     ]
    }
   ],
   "source": [
    "embedding_result = openai.Embedding.create(input = '저는 배가 고파요', model=\"text-embedding-ada-002\")['data'][0]['embedding']\n",
    "print(embedding_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>저는 배가 고파요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>저기 배가 지나가네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>굶어서 허기가 지네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>허기 워기라는 게임이 있는데 즐거워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>스팀에서 재밌는 거 해야지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>스팀에어프라이어로 연어구이 해먹을거야</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text\n",
       "0             저는 배가 고파요\n",
       "1           저기 배가 지나가네요\n",
       "2           굶어서 허기가 지네요\n",
       "3   허기 워기라는 게임이 있는데 즐거워\n",
       "4        스팀에서 재밌는 거 해야지\n",
       "5  스팀에어프라이어로 연어구이 해먹을거야"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['저는 배가 고파요',\n",
    "        '저기 배가 지나가네요',\n",
    "        '굶어서 허기가 지네요',\n",
    "        '허기 워기라는 게임이 있는데 즐거워',\n",
    "        '스팀에서 재밌는 거 해야지',\n",
    "        '스팀에어프라이어로 연어구이 해먹을거야']\n",
    "\n",
    "df = pd.DataFrame(data, columns=['text'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>저는 배가 고파요</td>\n",
       "      <td>[-0.01643836498260498, -0.021926594898104668, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>저기 배가 지나가네요</td>\n",
       "      <td>[-0.002701738616451621, -0.028862077742815018,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>굶어서 허기가 지네요</td>\n",
       "      <td>[-0.005840584635734558, -0.007400696165859699,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>허기 워기라는 게임이 있는데 즐거워</td>\n",
       "      <td>[-0.011341209523379803, -0.011656243354082108,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>스팀에서 재밌는 거 해야지</td>\n",
       "      <td>[-0.015407744795084, -0.014045882038772106, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>스팀에어프라이어로 연어구이 해먹을거야</td>\n",
       "      <td>[-0.0021207586396485567, -0.03023245744407177,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text                                          embedding\n",
       "0             저는 배가 고파요  [-0.01643836498260498, -0.021926594898104668, ...\n",
       "1           저기 배가 지나가네요  [-0.002701738616451621, -0.028862077742815018,...\n",
       "2           굶어서 허기가 지네요  [-0.005840584635734558, -0.007400696165859699,...\n",
       "3   허기 워기라는 게임이 있는데 즐거워  [-0.011341209523379803, -0.011656243354082108,...\n",
       "4        스팀에서 재밌는 거 해야지  [-0.015407744795084, -0.014045882038772106, 0....\n",
       "5  스팀에어프라이어로 연어구이 해먹을거야  [-0.0021207586396485567, -0.03023245744407177,..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embedding_func(text):\n",
    "    embedding_result = openai.Embedding.create(input = text, model=\"text-embedding-ada-002\")['data'][0]['embedding']\n",
    "    return embedding_result\n",
    "\n",
    "df['embedding'] = df.apply(lambda row: embedding_func(row.text), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터1과 벡터2의 유사도 : 0.6666666666666667\n",
      "벡터1과 벡터3의 유사도 : 0.6666666666666667\n",
      "벡터2와 벡터3의 유사도 : 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "def cos_sim(A, B):\n",
    "  return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "vec1 = np.array([0,1,1,1])\n",
    "vec2 = np.array([1,0,1,1])\n",
    "vec3 = np.array([2,0,2,2])\n",
    "\n",
    "print('벡터1과 벡터2의 유사도 :',cos_sim(vec1, vec2))\n",
    "print('벡터1과 벡터3의 유사도 :',cos_sim(vec1, vec3))\n",
    "print('벡터2와 벡터3의 유사도 :',cos_sim(vec2, vec3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_answer_candidate(df, query):\n",
    "    query_embedding = embedding_func(query)\n",
    "    df[\"similarity\"] = df.embedding.apply(lambda x: cos_sim(np.array(x),\n",
    "                                                            np.array(query_embedding)))\n",
    "    top_three_doc = df.sort_values(\"similarity\",\n",
    "                                ascending=False).head(3)\n",
    "    return top_three_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>굶어서 허기가 지네요</td>\n",
       "      <td>[-0.005840584635734558, -0.007400696165859699,...</td>\n",
       "      <td>0.838963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>스팀에어프라이어로 연어구이 해먹을거야</td>\n",
       "      <td>[-0.0021207586396485567, -0.03023245744407177,...</td>\n",
       "      <td>0.821658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>저는 배가 고파요</td>\n",
       "      <td>[-0.01643836498260498, -0.021926594898104668, ...</td>\n",
       "      <td>0.814633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text                                          embedding  \\\n",
       "2           굶어서 허기가 지네요  [-0.005840584635734558, -0.007400696165859699,...   \n",
       "5  스팀에어프라이어로 연어구이 해먹을거야  [-0.0021207586396485567, -0.03023245744407177,...   \n",
       "0             저는 배가 고파요  [-0.01643836498260498, -0.021926594898104668, ...   \n",
       "\n",
       "   similarity  \n",
       "2    0.838963  \n",
       "5    0.821658  \n",
       "0    0.814633  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_result = return_answer_candidate(df, '아무 것도 안 먹었더니 꼬르륵 소리가나네')\n",
    "sim_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain 사용하여 PDF 내용에 질문하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF 추출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 불러오기\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일 경로를 지정하여 불러오기. \n",
    "pdf_reader = PdfReader('Summary of ChatGPTGPT-4 Research.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 추출하기\n",
    "total_text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    total_text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of ChatGPT/GPT-4 Research\n",
      "and Perspective Towards the Future of Large\n",
      "Language Models\n",
      "Yiheng Liu\u00031, Tianle Han∗1, Siyuan Ma1, Jiayue Zhang1,\n",
      "Yuanyuan Yang1, Jiaming Tian1, Hao He1, Antong Li2, Mengshen\n",
      "He1, Zhengliang Liu3, Zihao Wu3, Dajiang Zhu4, Xiang Li5, Ning\n",
      "Qiang1, Dingang Shen6,7,8, Tianming Liu3, and Bao Ge†1\n",
      "1School of Physics and Information Technology, Shaanxi Normal University, Xi'an\n",
      "710119 China\n",
      "2School of Life and Technology Biomedical-Engineering, Xi'an Jiaotong University,\n",
      "Xi'an 710049, China\n",
      "3School of Computing, The University of Georgia, Athens 30602, USA\n",
      "4Department of Computer Science and Engineering, The University of Texas at\n",
      "Arlington, Arlington 76019, USA\n",
      "5Department of Radiology, Massachusetts General Hospital and Harvard Medical\n",
      "School, Boston 02115, USA\n",
      "6School of Biomedical Engineering, ShanghaiTech University, Shanghai 201210,\n",
      "China\n",
      "7Shanghai United Imaging Intelligence Co., Ltd., Shanghai 200230, China\n",
      "8Shanghai Clinical Research and Trial Center, Shanghai 201210, China\n",
      "Abstract\n",
      "This paper presents a comprehensive survey of ChatGPT and GPT-4,\n",
      "state-of-the-art large language models (LLM) from the GPT series, and\n",
      "their prospective applications across diverse domains. Indeed, key innova-\n",
      "tions such as large-scale pre-training that captures knowledge across the\n",
      "entire world wide web, instruction \fne-tuning and Reinforcement Learn-\n",
      "ing from Human Feedback (RLHF) have played signi\fcant roles in en-\n",
      "hancing LLMs' adaptability and performance. We performed an in-depth\n",
      "analysis of 194 relevant papers on arXiv, encompassing trend analysis,\n",
      "word cloud representation, and distribution analysis across various appli-\n",
      "cation domains. The \fndings reveal a signi\fcant and increasing interest\n",
      "in ChatGPT/GPT-4 research, predominantly centered on direct natural\n",
      "language processing applications, while also demonstrating considerable\n",
      "potential in areas ranging from education and history to mathematics,\n",
      "∗Co-\frst author\n",
      "†Corresponding author: bob ge@snnu.edu.cn\n",
      "1arXiv:2304.01852v1  [cs.CL]  4 Apr 2023medicine, and physics. This study endeavors to furnish insights into Chat-\n",
      "GPT's capabilities, potential implications, ethical concerns, and o\u000ber di-\n",
      "rection for future advancements in this \feld.\n",
      "1 Introduction\n",
      "Recent advances in natural language processing (NLP) have led to the devel-\n",
      "opment of powerful language models such as the GPT (Generative Pre-trained\n",
      "Transformer) series [1, 2, 3, 4, 5], including large language models (LLM) such\n",
      "as ChatGPT and GPT-4. These models are pre-trained on vast amounts of\n",
      "text data and have demonstrated exceptional performance in a wide range of\n",
      "NLP tasks, including language translation, text summarization, and question-\n",
      "answering. In particular, the ChatGPT model has demonstrated its potential\n",
      "in various \felds, including education, healthcare, reasoning, text generation,\n",
      "human-machine interaction, and scienti\fc research.\n",
      "A key milestone of LLM development is InstructGPT [5], a framework that\n",
      "allows for instruction \fne-tuning of a pre-trained language model based on Re-\n",
      "inforcement Learning from Human Feedback (RLHF) [6, 5]. This framework\n",
      "enables an LLM to adapt to a wide range of NLP tasks, making it highly ver-\n",
      "exible by leveraging human feedback. RLHF enables the model to\n",
      "align with human preferences and human values, which signi\fcantly improves\n",
      "from large language models that are solely trained text corpora through unsu-\n",
      "pervised pre-training. ChatGPT is a successor to InstructGPT. Since its release\n",
      "in December 2022, ChatGPT has been equipped with these advanced develop-\n",
      "ments, leading to impressive performances in various downstream NLP tasks\n",
      "such as reasoning and generalized text generation. These unprecedented NLP\n",
      "capabilities spur applications in diverse domains such as education, healthcare,\n",
      "human-machine interaction, medicine and scienti\fc research. ChatGPT has re-\n",
      "ceived widespread attention and interest, leading to an increasing number of\n",
      "applications and research that harness its exceeding potential. The open release\n",
      "of the multi-modal GPT-4 model further expands the horizon of large language\n",
      "models and empowers exciting developments that involve diverse data beyond\n",
      "text.\n",
      "The purpose of this paper is to provide a comprehensive survey of the existing\n",
      "research on ChatGPT and its potential applications in various \felds. To achieve\n",
      "this goal, we conducted a thorough analysis of papers related to ChatGPT in\n",
      "the arXiv repository. As of April 1st, 2023, there are a total of 194 papers\n",
      "mentioning ChatGPT on arXiv. In this study, we conducted a trend analysis of\n",
      "these papers and generated a word cloud to visualize the commonly used terms.\n",
      "Additionally, we also examined the distribution of the papers across various\n",
      "\felds and presented the corresponding statistics. Figure 1 displays the daily\n",
      "submission trend of papers related to ChatGPT, indicating a growing interest\n",
      "in this \feld. Figure 2 illustrates the word cloud analysis of all the papers. We\n",
      "can observe that the current research is primarily focused on natural language\n",
      "processing, but there is still signi\fcant potential for research in other \felds such\n",
      "2Figure 1: The number of papers submitted by researchers per day.\n",
      "3Figure 2: Word cloud analysis of all the 194 papers.\n",
      "as education and history. This is further supported by Figure 3, which displays\n",
      "the distribution of submitted papers across various \felds, highlighting the need\n",
      "for more research and development in these areas.\n",
      "This paper aims to shed light on the promising capabilities of ChatGPT\n",
      "and provide insight into its potential impact in the future, including ethical\n",
      "considerations. Through this survey, we hope to provide insights into how these\n",
      "models can be improved and extended in the future. In section 2, we will\n",
      "review the existing work related to ChatGPT, including its applications, ethical\n",
      "considerations, and evaluation. In addition to discussing the current state of\n",
      "research related to ChatGPT, we will also explore its limitations in section 3.\n",
      "Furthermore, we will provide guidance on future directions for language model\n",
      "development.\n",
      "2 Related work of ChatGPT\n",
      "In this section, we review the latest research related to the application, ethics,\n",
      "and evaluation of ChatGPT.\n",
      "2.1 Application of ChatGPT\n",
      "2.1.1 Question And Answering\n",
      "In the education \feld\n",
      "ChatGPT is commonly used for question and answers testing in the edu-\n",
      "cation sector. Users can use ChatGPT to learn, compare and verify answers\n",
      "for di\u000berent academic subjects such as physics, mathematics, and chemistry,\n",
      "4Figure 3: The distribution of submitted papers across various \felds.\n",
      "5and/or conceptual subjects such as philosophy and religion. Additionally, users\n",
      "can ask open-ended and analytical questions to understand the capabilities of\n",
      "ChatGPT.\n",
      "In the \feld of mathematics, Frieder et al. [7] constructed the GHOSTS nat-\n",
      "ural language dataset, which consists of graduate-level math test questions.\n",
      "The authors tested ChatGPT's math abilities on the GHOSTS dataset us-\n",
      "ing a question-and-answer format and evaluated it according to \fne-grained\n",
      "standards.In the Grad Text dataset, which covers simple set theory and logic\n",
      "problems, ChatGPT performed the best. However, in the Olympiad-Problem-\n",
      "Solving dataset, ChatGPT performed poorly, receiving only two 4-point scores\n",
      "(out of a total of 5), with the majority of scores being 2 points. In the Holes-\n",
      "in-Proofs dataset, ChatGPT received the lowest score of 1 point. In the MATH\n",
      "dataset, ChatGPT only scored impressively in 26% of cases. These results sug-\n",
      "gest that ChatGPT's math abilities are clearly lower than those of ordinary\n",
      "math graduate students. Although ChatGPT can generally understand math\n",
      "problems, it fails to provide the correct solutions. Pardos et al. [8] used the\n",
      "Open Adaptive Tutoring system (OATutor) to investigate whether prompts gen-\n",
      "erated by ChatGPT were helpful for learning algebra, with 77 participants from\n",
      "Mechanical Turk taking part in the experiment. The experiment used ques-\n",
      "tions from OpenStax's Elementary and Intermediate Algebra textbooks. These\n",
      "participants were randomly assigned to either a control group (with manual\n",
      "prompts) or an experimental group (with ChatGPT prompts). For each ques-\n",
      "tion in both courses, the authors obtained answers from ChatGPT through a\n",
      "question-and-answer format and evaluated scores according to three criteria:\n",
      "ChatGPT provided an answer, the answer was correct, and inappropriate lan-\n",
      "guage was not used in the answer. The study found that 70% of prompts gener-\n",
      "ated by ChatGPT passed manual quality checks, and both humans and Chat-\n",
      "GPT produced positive learning gains. However, the scores of human prompts\n",
      "ranged from 74.59% to 84.32%, signi\fcantly higher than those of ChatGPT\n",
      "prompts. Shakarian et al. [9] studied the performance of ChatGPT on math\n",
      "word problems (MWPs), using the DRAW-1K dataset for experimentation. The\n",
      "dataset consists of 1000 MWPs and their answers, along with algebraic equa-\n",
      "tion templates for solving such problems. The authors used the idea of machine\n",
      "learning introspection and built performance prediction models using random\n",
      "forests and XGBoost, and evaluated them on the dataset using \fve-fold cross-\n",
      "validation. ChatGPT's accuracy increased from an initial 34% to a \fnal 69%,\n",
      "while its recall increased from an initial 41% to a \fnal 83%. The authors also\n",
      "found that ChatGPT's failure rate decreased from an initial 84% to a \fnal\n",
      "20%, indicating that performance can vary greatly depending on speci\fc job\n",
      "requirements.\n",
      "In the \feld of physics, Lehnert et al. [10] explored the capabilities and limita-\n",
      "tions of ChatGPT by studying how it handles obscure physics topics such as the\n",
      "swamp land conjecture in string theory. The experimental dialogue began with\n",
      "broader and more general questions in the \feld of string theory before narrowing\n",
      "down to speci\fc swamp land conjectures and examining ChatGPT's understand-\n",
      "ing of them. The study found that ChatGPT could de\fne and explain di\u000berent\n",
      "6concepts in various styles, but was not e\u000bective in truly connecting various con-\n",
      "cepts. It would con\fdently provide false information and fabricate statements\n",
      "when necessary, indicating that ChatGPT cannot truly create new knowledge\n",
      "or establish new connections. However, in terms of identifying analogies and\n",
      "describing abstract concepts of visual representation, ChatGPT can cleverly\n",
      "use language. Kortemeyer et al. [11] evaluated ChatGPT's ability to answer\n",
      "calculus-based physics questions through a question-and-answer test. The tests\n",
      "included online homework, clicker questions, programming exercises, and exams\n",
      "covering classical mechanics, thermodynamics, electricity and magnetism, and\n",
      "modern physics. While ChatGPT was able to pass the course, it also demon-\n",
      "strated many misconceptions and errors commonly held by beginners. West et\n",
      "al. [12] used the Force Concept Inventory (FCI) to evaluate ChatGPT's accu-\n",
      "racy in answering physics concept problems related to kinematics and Newtonian\n",
      "mechanics in the \frst semester of college physics. The FCI covers topics such\n",
      "as kinematics, projectile motion, free fall, circular motion, and Newton's laws.\n",
      "The study included data from 415 students who took the FCI at the end of the\n",
      "semester, with an average score of 56%, while ChatGPT scored approximately\n",
      "between 50% to 65%. The authors demonstrated that ChatGPT's performance\n",
      "in physics learning can reach or even exceed the average level of a semester of\n",
      "college physics.\n",
      "In the medical \feld\n",
      "ChatGPT's question-answering capabilities can also be applied in the med-\n",
      "ical \feld, such as for answering medical questions from patients or assisting\n",
      "healthcare professionals in diagnosing diseases. Nov et al. [13] evaluated the fea-\n",
      "sibility of using ChatGPT for patient-doctor communication. The experiment\n",
      "extracted 10 representative patient-doctor interactions from EHR, placed the\n",
      "patient's questions in ChatGPT, and asked ChatGPT to respond using roughly\n",
      "the same number of words as the doctor's response. Each patient's question was\n",
      "answered by either the doctor or ChatGPT, and the patient was informed that\n",
      "5 were answered by the doctor and 5 were generated by ChatGPT, and was\n",
      "asked to correctly identify the source of the response. The results of the exper-\n",
      "iment showed that the probability of correctly identifying ChatGPT's response\n",
      "was 65.5%, while the probability of correctly identifying the doctor's response\n",
      "was 65.1%. In addition, the experiment found that the patient's response to\n",
      "the trustworthiness of ChatGPT's function was weakly positive (average Likert\n",
      "score: 3.4), and trust decreased as the complexity of health-related tasks in\n",
      "the questions increased. ChatGPT's responses to patient questions were only\n",
      "slightly di\u000berent from those of doctors, but people seem to trust ChatGPT to\n",
      "answer low-risk health questions, while for complex medical questions, people\n",
      "still tend to trust the doctor's responses and advice.\n",
      "Tu et al. [14] explored the causal discovery ability of ChatGPT in the diag-\n",
      "nosis of neuropathic pain. Causal relationship discovery aims to reveal potential\n",
      "unknown causal relationships based purely on observed data [15]. The experi-\n",
      "mental results found that ChatGPT has some limitations in understanding new\n",
      "7knowledge and concepts beyond the existing textual training data corpus, that\n",
      "is, it only understands language commonly used to describe situations and not\n",
      "underlying knowledge. In addition, its performance consistency and stability are\n",
      "not high, as the experiment observed that it would provide di\u000berent answers for\n",
      "the same question under multiple inquiries. However, despite the many limita-\n",
      "tions of ChatGPT, we believe that it has a great opportunity to improve causal\n",
      "relationship research.\n",
      "In the other \feld\n",
      "Guo et al. [16] attempted to apply ChatGPT in the \feld of communication,\n",
      "speci\fcally using ChatGPT for ordered importance semantic communication,\n",
      "where ChatGPT plays the role of an intelligent consulting assistant that can\n",
      "replace humans in identifying the semantic importance of words in messages and\n",
      "can be directly embedded into the current communication system. For a message\n",
      "to be transmitted, the sender \frst utilizes ChatGPT to output the semantic\n",
      "importance order of each word. Then, the transmitter executes an unequal error\n",
      "protection transmission strategy based on the importance order to make the\n",
      "transmission of important words in the message more reliable. The experimental\n",
      "results show that the error rate and semantic loss of important words measured\n",
      "in the communication system embedded with ChatGPT are much lower than\n",
      "those of existing communication schemes, indicating that ChatGPT can protect\n",
      "important words well and make semantic communication more reliable.\n",
      "Wang et al. [17] studied the e\u000bectiveness of ChatGPT in generating high-\n",
      "quality Boolean queries for systematic literature search. They designed a wide\n",
      "range of prompts and investigated these tasks on more than 100 systematic\n",
      "review topics. In the end, queries generated by ChatGPT achieved higher accu-\n",
      "racy compared to the currently most advanced query generation methods but\n",
      "at the cost of reduced recall. For time-limited rapid reviews, it is often accept-\n",
      "able to trade o\u000b higher precision for lower recall. Additionally, ChatGPT can\n",
      "generate high search accuracy Boolean queries by guiding the prompts. How-\n",
      "ever, it should be noted that when two queries use the same prompts, ChatGPT\n",
      "generates di\u000berent queries, indicating its limitations in consistency and stabil-\n",
      "ity. Overall, this study demonstrated the potential of ChatGPT in generating\n",
      "e\u000bective Boolean queries for systematic literature searches.\n",
      "2.1.2 Text Classi\fcation\n",
      "The purpose of text classi\fcation is to assign text data to prede\fned categories.\n",
      "This task is critical for many applications, including sentiment analysis, spam\n",
      "detection, and topic modeling. While traditional machine learning algorithms\n",
      "have been widely used for text classi\fcation, recent advances in natural lan-\n",
      "guage processing have led to the development of more advanced techniques.\n",
      "ChatGPT has shown immense potential in this \feld. Its ability to accurately\n",
      "exibility in handling various classi\fcation tasks, and potential for\n",
      "customization make it a valuable tool for text classi\fcation, as evidenced by\n",
      "several studies in the literature.\n",
      "8Kuzman et al. [18] employed ChatGPT for automatic genre recognition, with\n",
      "the goal of simplifying the text classi\fcation task by utilizing ChatGPT's zero-\n",
      "shot classi\fcation capability. They compared ChatGPT's genre recognition per-\n",
      "formance, using two prompt languages (EN and SL), with the X-GENRE clas-\n",
      "si\fer based on the multilingual model XLM-RoBERTa on the English dataset\n",
      "EN-GINCO and the Slovenian dataset GINCO. The results showed that when\n",
      "EN was used as the prompt language, ChatGPT achieved Micro F1, Macro F1,\n",
      "and Accuracy scores of 0.74, 0.66, and 0.72. However, on the GINCO dataset,\n",
      "ChatGPT's genre recognition performance with both EN and SL prompt lan-\n",
      "guages was lower than that of the X-GENRE classi\fer to varying degrees.\n",
      "Amin et al. [19] evaluated the text classi\fcation ability of ChatGPT in\n",
      "a\u000bective computing by using it to perform personality prediction, sentiment\n",
      "analysis, and suicide ideation detection tasks. They prompted ChatGPT with\n",
      "corresponding prompts on three datasets: First Impressions, Sentiment140, and\n",
      "Suicide and Depression, and compared its classi\fcation performance with three\n",
      "baseline models: RoBERTa-base, Word2Vec, and BoW. The results showed\n",
      "that ChatGPT's accuracy and UAR for the \fve personality classi\fcations on\n",
      "the First Impressions dataset were lower than the baseline methods to varying\n",
      "degrees. On the Sentiment140 dataset, ChatGPT's accuracy and UAR were 85.5\n",
      "and 85.5, respectively, which were better than the three baseline methods. On\n",
      "the Suicide and Depression dataset, ChatGPT's accuracy and UAR were 92.7\n",
      "and 91.2, respectively, which were lower than RoBERTa, the best-performing\n",
      "baseline method.\n",
      "Zhang et al. [20] employed ChatGPT for stance detection, which includes\n",
      "support and opposition. They used ChatGPT to classify the political stance\n",
      "of tweets in the SemEval-2016 and P-Stance datasets. SemEval-2016 contains\n",
      "4,870 English tweets, and they selected tweets with the most commonly occur-\n",
      "ring FM, LA, and HC political labels for stance classi\fcation. The P-Stance\n",
      "dataset has 21,574 English tweets, and they classi\fed the stance of tweets to-\n",
      "wards Trump, Biden, and Bernie. The \fnal results showed that on the SemEval-\n",
      "2016 dataset, ChatGPT achieved F1-m scores of 68.4, 58.2, and 79.5 for the FM,\n",
      "LA, and HC political labels, and F1-avg scores of 72.6, 59.3, and 78.0, respec-\n",
      "tively. On the P-Stance dataset, ChatGPT achieved F1-m scores of 82.8, 82.3,\n",
      "and 79.4 for the Trump, Biden, and Bernie political \fgures, and F1-avg scores\n",
      "of 83.2, 82.0, and 79.4, respectively.\n",
      "Huang et al. [21] used ChatGPT to detect implicit hate speech in tweets.\n",
      "They selected 12.5% (795 tweets) of the LatentHatred dataset containing im-\n",
      "plicit hate speech and asked ChatGPT to classify them into three categories:\n",
      "implicit hate speech, non-hate speech, and uncertain. The results showed that\n",
      "ChatGPT correctly recognized 636 (80%) of the tweets. The number of tweets\n",
      "classi\fed as non-hate speech and uncertain were 146 (18.4%) and 13 (1.6%),\n",
      "respectively. The results of the reclassi\fcation of tweets in the non-hate speech\n",
      "and uncertain categories by Amazon Mechanical Turk (Mturk) workers were\n",
      "consistent with ChatGPT's classi\fcation.\n",
      "Overall, ChatGPT has tremendous potential in text classi\fcation tasks, as it\n",
      "can e\u000bectively address problems such as genre identi\fcation, sentiment analysis,\n",
      "9stance detection, and more. However, there are still challenges that ChatGPT\n",
      "faces in the \feld of text classi\fcation. Firstly, it struggles to perform well in\n",
      "classi\fcation tasks with rare or out-of-vocabulary words since it heavily relies\n",
      "on the distribution of training data. Additionally, the signi\fcant computational\n",
      "resources required for training and utilizing ChatGPT can limit its use in some\n",
      "applications.\n",
      "2.1.3 Text generation\n",
      "We live in an era of information explosion, and text is an e\u000ecient way of trans-\n",
      "mitting information. The diversity of information has led to a diversity of text\n",
      "categories. When researchers use ChatGPT's text generation capabilities for\n",
      "research, they inevitably choose to generate di\u000berent types of text. In the pro-\n",
      "cess of reading papers, we found that the word count of the text generated by\n",
      "researchers increased from small to large, so we wanted to summarize existing\n",
      "research based on the size of the text word count. We divided the generated\n",
      "text into three levels: phrases, sentences, and paragraphs.\n",
      "The following article uses ChatGPT to generate phrases. Zhang et al. [22]\n",
      "proves that the semantic HAR model with semantic augmentation added dur-\n",
      "ing training performs better in motion recognition than other models. Semantic\n",
      "augmentation requires shared tokens, which is lacking in some datasets. There-\n",
      "fore, authors leverage ChatGPT for an automated label generation approach\n",
      "for datasets originally without shared tokens. Fu et al. [23] describes a new\n",
      "ow for converting natural language commands into Bash commands. The\n",
      "author uses ChatGPT to generate a candidate list of Bash commands based\n",
      "on user input, and then uses a combination of heuristic and machine learning\n",
      "ow wasques to rank and select the most likely candidates. This work\n",
      "evaluated on a real command dataset and achieved high accuracy compared\n",
      "to other state-of-the-art methods. Chen et al. [24] used the Bart model and\n",
      "ChatGPT for the task of summarizing humorous titles and compared the perfor-\n",
      "mance of the two models. It was found that the Bart model performed better on\n",
      "large datasets, but ChatGPT was competitive with our best \fne-tuned model\n",
      "in a small range (48), albeit slightly weaker.\n",
      "The following article uses ChatGPT to generate sentences.Chen et al. [25]\n",
      "constructed a dialogue dataset (HPD) with scenes, timelines, character at-\n",
      "tributes, and character relationships in order to use ChatGPT as a conver-\n",
      "sational agent to generate dialogue. However, ChatGPT's performance on the\n",
      "test set was poor, and there is room for improvement.In study [26], chatGPT\n",
      "demonstrated its ability to simplify complex text by providing three \fctional\n",
      "radiology reports to chatGPT for simpli\fcation. Most radiologists found the\n",
      "simpli\fed reports to be accurate and complete, with no potential harm to pa-\n",
      "tients. However, some errors, omissions of critical medical information and text\n",
      "passages were identi\fed, which could potentially lead to harmful conclusions if\n",
      "not understood by the physicians. Xia et al. [27] proposes a new program re-\n",
      "pair paradigm called Session-based Automatic Program Repair (APR). In APR,\n",
      "the previously generated patches are iteratively built upon by combining them\n",
      "10with validation feedback to construct the model's input. The e\u000bectiveness of\n",
      "the approach is veri\fed using the QuixBugs dataset. The experiment shows\n",
      "that ChatGPT \fne-tuned with reinforcement learning from human feedback\n",
      "(RLHF) outperforms Codex trained unsupervisedly in both repair datasets. In\n",
      "reference to study [28], ChatGPT was compared to three commercial transla-\n",
      "tion products: Google Translate2, DeepL Translate3, and Tencent TranSmart4.\n",
      "The evaluation was conducted on the Flores101 test set, using the WMT19\n",
      "biomedical translation task to test translation robustness, with BLEU score as\n",
      "the main metric. The study found that ChatGPT is competitive with commer-\n",
      "cial translation products on high-resource European languages but falls behind\n",
      "on low-resource or distant languages. The authors explored an interesting strat-\n",
      "egy called pivot prompts, which signi\fcantly improved translation performance.\n",
      "While ChatGPT did not perform as well as commercial systems on biomedical\n",
      "abstracts or Reddit comments, it may be a good speech translator. Prieto et\n",
      "al. [29] evaluated the use of ChatGPT in developing an automated construction\n",
      "schedule based on natural language prompts. The experiment required building\n",
      "new partitions in an existing space and providing details on the rooms to be\n",
      "partitioned. The results showed that ChatGPT was able to generate a coher-\n",
      "ent schedule that followed a logical approach to meet the requirements of the\n",
      "aws that would limit theere were still several major \n",
      "use of this tool in real-world projects.Michail et al. [30] proposed a method\n",
      "to improve the prediction accuracy of the HeFit \fne-tuned XLM T model on\n",
      "tweet intimacy by generating a dataset of tweets with intimacy rating tags using\n",
      "ChatGPT. The speci\fc operation is to input tweets with intimacy rating tags\n",
      "into ChatGPT and then output similar tweets.\n",
      "The following article uses ChatGPT to generate paragraphs. Wang et al.\n",
      "[31] compared the abstract summarization performance of ChatGPT and other\n",
      "models on various cross-lingual text datasets and found that ChatGPT may\n",
      "perform worse in metrics such as R 1, R 2, R L, and B S. Yang et al. [32]\n",
      "summarized the performance of ChatGPT in question answering-based text\n",
      "summarization and found that, compared to \fne-tuned models, ChatGPT's\n",
      "performance is slightly worse in all performance metrics. However, the article\n",
      "suggests that if the dataset is golden annotation, ChatGPT's performance may\n",
      "surpass \fne-tuned models in these metrics. Belouadi et al. [33] compared the\n",
      "ability of ByGPT5 and ChatGPT trained on a range of labeled and unlabeled\n",
      "datasets of English and German poetry to generate constrained style poetry, and\n",
      "evaluated them using three metrics: Rhyme, ScoreAlliteration, and ScoreMe-\n",
      "ter Score. The conclusion is that ByGPT5 performs better than ChatGPT.\n",
      "Blanco-Gonzalez et al. [34] evaluated chatGPT's ability to write commentary\n",
      "articles, and in fact, this article itself was written by chatGPT. The human au-\n",
      "thor rewrote the manuscript based on chatGPT's draft. Experts found that it\n",
      "can quickly generate and optimize text, as well as help users complete multiple\n",
      "tasks. However, in terms of generating new content, it is not ideal. Ultimately,\n",
      "it can be said that without strong human intervention, chatGPT is not a use-\n",
      "ful tool for writing reliable scienti\fc texts. It lacks the knowledge and expertise\n",
      "required to accurately and fully convey complex scienti\fc concepts and informa-\n",
      "11tion. Khalil et al. [35] on the originality of content generated by ChatGPT. To\n",
      "evaluate the originality of 50 papers on various topics generated by ChatGPT,\n",
      "two popular plagiarism detection tools, Turnitin and iThenticate, were used.\n",
      "The results showed that ChatGPT has great potential in generating complex\n",
      "text output that is not easily captured by plagiarism detection software. The\n",
      "existing plagiarism detection software should update their plagiarism detection\n",
      "engines. Basic et al. [36] conducted a comparison of the writing performance\n",
      "of students using or not using ChatGPT-3 as a writing aid. The experiment\n",
      "consisted of two groups of 9 participants each. The control group wrote articles\n",
      "using traditional methods, while the experimental group used ChatGPT as an\n",
      "aid. Two teachers evaluated the papers. The study showed that the assistance of\n",
      "ChatGPT did not necessarily improve the quality of the students' essays.Noever\n",
      "et al. [37] discusses the potential of using arti\fcial intelligence (AI), particularly\n",
      "language models like GPT (including GPT-3), to create more convincing chat-\n",
      "bots that can deceive humans into thinking they are interacting with another\n",
      "person. The article describes a series of experiments in which they used GPT-3\n",
      "to generate chatbot responses that mimic human-like conversations and were\n",
      "tested on human participants. The results show that some participants were\n",
      "unable to distinguish between the chatbot and a real human, highlighting the\n",
      "potential for these AI chatbots to be used for deceptive purposes.\n",
      "2.1.4 Code Generation\n",
      "Code generation refers to the process of automatically generating computer code\n",
      "from high-level descriptions or speci\fcations. ChatGPT's advanced natural lan-\n",
      "guage processing capabilities make it capable of performing code generation\n",
      "tasks. By analyzing the requirements for code generation, ChatGPT can pro-\n",
      "duce code snippets that accurately execute the intended functionality. This not\n",
      "only saves time and e\u000bort in writing code from scratch but also reduces the risk\n",
      "of errors that may occur during manual coding. In addition, ChatGPT's ability\n",
      "to learn and adapt to new programming languages and frameworks enables it\n",
      "to complete more complex programming tasks. For example:\n",
      "Megahed et al. [38] discussed the potential of using ChatGPT for tasks\n",
      "such as code explanation, suggesting alternative methods for problem-solving\n",
      "with code, and translating code between programming languages. The solutions\n",
      "provided by ChatGPT were found to be viable. In another study, Treude et\n",
      "al. [39] introduced a ChatGPT-based prototype called GPTCOMCARE, which\n",
      "helps programmers generate multiple solutions for a programming problem and\n",
      "highlight the di\u000berences between each solution using colors.Sobania et al. [40]\n",
      "utilized ChatGPT for code bug \fxing, and further improved the success rate of\n",
      "bug \fxing by inputting more information through its dialogue system. Speci\f-\n",
      "cally, the QuixBugs standard bug \fxing benchmark contained 40 code bugs that\n",
      "needed to be \fxed. With limited information, ChatGPT \fxed 19 bugs, which\n",
      "was slightly lower than the 21 bugs \fxed by the Codex model, but signi\fcantly\n",
      "higher than the 7 \fxed by the Standard APR model. When given more prompts\n",
      "and information, ChatGPT was able to \fx 31 bugs, demonstrating its potential\n",
      "12for code bug \fxing tasks.Xia et al. [27] proposed a conversational approach\n",
      "for Automated Program Repair (APR), which alternates between generating\n",
      "patches and validating them against feedback from test cases until the correct\n",
      "patch is generated. Selecting 30 bugs from the QuixBugs standard bug \fxing\n",
      "benchmark, which are suitable for test case feedback, and demonstrating them\n",
      "with Java and Python, the QuixBugs-Python and QuixBugs-Java datasets were\n",
      "obtained. The conversational APR using ChatGPT outperformed the conversa-\n",
      "tional APR using Codex and the conversational APR using CODEGEN (with\n",
      "model parameters of 350M, 2B, 6B, and 16B) on both datasets. Furthermore,\n",
      "ChatGPT's conversational APR generated and validated patches with signi\f-\n",
      "cantly fewer feedback loops than the other models.\n",
      "ChatGPT can not only be used to achieve some simple code generation tasks\n",
      "but also can be used to accomplish some complex programming tasks. Noever\n",
      "et al. [41] tested ChatGPT's code generation capabilities on four datasets -\n",
      "Iris, Titanic, Boston Housing, and Faker. When prompted to mimic a Python\n",
      "interpreter in the form of a Jupyter notebook, the model was able to generate\n",
      "independent code based on the prompt and respond with the expected out-\n",
      "put. For example, when given the prompt \"data.cor()\" for the Iris dataset,\n",
      "ChatGPT generated correct Python output. The test results indicate that\n",
      "ChatGPT can access structured datasets and perform basic software opera-\n",
      "tions required by databases, such as create, read, update, and delete (CRUD).\n",
      "This suggests that cutting-edge language models like ChatGPT have the nec-\n",
      "essary scale to tackle complex problems. McKee et al. [42] utilized ChatGPT\n",
      "as an experimental platform to investigate cybersecurity issues. They modeled\n",
      "\fve di\u000berent modes of computer virus properties, including self-replication, self-\n",
      "modi\fcation, execution, evasion, and application, using ChatGPT. These \fve\n",
      "modes encompassed thirteen encoding tasks from credential access to defense\n",
      "evasion within the MITRE ATT&CK framework. The results showed that the\n",
      "quality of ChatGPT's generated code was generally above average, except for the\n",
      "self-replication mode, where it performed poorly.They [43] also employed Chat-\n",
      "GPT as a network honeypot to defend against attackers. By having ChatGPT\n",
      "mimic Linux, Mac, and Windows terminal commands and providing interfaces\n",
      "for TeamViewer, nmap, and ping, a dynamic environment can be created to\n",
      "adapt to attackers' operations, and logs can be used to gain insight into their\n",
      "attack methods, tactics, and procedures. The authors demonstrated ten hon-\n",
      "eypot tasks to illustrate that ChatGPT's interface not only provides su\u000ecient\n",
      "API memory to execute previous commands without defaulting to repetitive\n",
      "introductory tasks but also o\u000bers a responsive welcome program that maintains\n",
      "attackers' interest in multiple queries.\n",
      "In the \feld of code generation, there are still several challenges with Chat-\n",
      "GPT. Firstly, its application scope is limited as its training data is biased to-\n",
      "wards programming languages such as Python, C++, and Java, making it po-\n",
      "tentially unsuitable for some programming languages or coding styles. Secondly,\n",
      "manual optimization is necessary for code formatting, as the generated code may\n",
      "not be performance-optimized or follow best coding practices, requiring manual\n",
      "editing and optimization. Lastly, the quality of the generated code cannot be\n",
      "13guaranteed, as it heavily relies on the quality of the natural language input,\n",
      "which may contain errors, ambiguities, or inconsistencies, ultimately a\u000becting\n",
      "the accuracy and reliability of the generated code.\n",
      "2.1.5 Inference\n",
      "Inference refers to the process of drawing new conclusions or information through\n",
      "logical deduction from known facts or information. It is typically based on a se-\n",
      "ries of premises or assumptions, and involves applying logical rules or reasoning\n",
      "methods to arrive at a conclusion. Inference is an important ability in human\n",
      "thinking, and is often used to solve problems, make decisions, analyze and eval-\n",
      "uate information, etc. Inference also plays a key role in \felds such as science,\n",
      "philosophy, law, etc. There are two types of inference: inductive reasoning,\n",
      "which involves deriving general rules or conclusions from known facts or expe-\n",
      "riences, and deductive reasoning, which involves deriving speci\fc conclusions\n",
      "from known premises or assumptions. Whether inductive or deductive, the pro-\n",
      "cess of inference requires following strict logical rules to ensure the correctness\n",
      "and reliability of the inference.\n",
      "Some papers attempt to use ChatGPT's ability in inductive reasoning to\n",
      "capture the meaning in text and use de\fned metrics to score the text. Michail\n",
      "et al. [30] uses ChatGPT to infer intimacy expressed in tweets. They \frst input\n",
      "50 tweets with intimacy markers to ChatGPT, then use inductive reasoning to\n",
      "infer the standards for generating tweets with di\u000berent levels of intimacy, and\n",
      "\fnally generate ten tweets with intimacy values ranging from 0 to 5. Susnjak\n",
      "et al. [44] collected a large amount of textual data from patient-doctor dis-\n",
      "cussion forums, patient testimonials, social media platforms, medical journals,\n",
      "and other scienti\fc research publications. Using the BERT model, the author\n",
      "inferred emotion values from 0 to 1. The author visualized the process of how\n",
      "the presence of bias in the discourse surrounding chronic manifestations of the\n",
      "disease using the SHAP tool. The author also envisioned ChatGPT as a replace-\n",
      "ment for the BERT model for scoring the emotional value of text. Huang et al.\n",
      "[21] chose 12.5% of individuals in the potential hate dataset as study materials,\n",
      "induced ChatGPT to make classi\fcations based on a prompt, and ChatGPT\n",
      "produced three classi\fcations: unclear, yes, and no. The author assigned a\n",
      "value of 1 to yes, -1 to no, and 0 to unclear, and had ChatGPT score and clas-\n",
      "sify them. ChatGPT was able to correctly classify 80% of implicit hate tweets\n",
      "in the author's experimental setup, demonstrating ChatGPT's great potential\n",
      "as a data labeling tool using simple prompts.\n",
      "Some papers have evaluated ChatGPT's reasoning performance, mainly in\n",
      "decision-making and spatial reasoning, and identifying ambiguity. Tang et al.\n",
      "[45] used the independence axiom and the transitivity axiom, as well as other\n",
      "non-VNM related decision-making abilities, by presenting bets conditioned on\n",
      "random events, bets with asymmetric outcomes, decisions encapsulating Sav-\n",
      "age's Sure Thing principle, and other complex bet structures like nested bets, to\n",
      "design experiments where each experiment input a short prompt to ChatGPT\n",
      "and evaluated the results. The conclusion is that ChatGPT exhibits uncer-\n",
      "14tainty in the decision-making process: in some cases, large language models\n",
      "can arrive at the correct answer through incorrect reasoning; and it may make\n",
      "suboptimal decisions for simple reasoning problems. Ortega-Martn et al. [46]\n",
      "had ChatGPT detect three di\u000berent levels of language ambiguity and evaluated\n",
      "its performance. The conclusion is that In semantics, ChatGPT performed per-\n",
      "fectly in the detection of ambiguities. Apart from that, it has some bright sports\n",
      "(co-reference resolution) and some weaknesses (puts gender bias over grammar\n",
      "in some non-ambiguous situations). In the generation task ChatGPT did well,\n",
      "but also revealed some of its worse issues: the lack of systematicity. Lastly, it\n",
      "should also be pointed that in most of the cases ChatGPT brilliantly alludes to\n",
      "lack of context as the key factor in disambiguation.\n",
      "2.1.6 Data or information extraction, transformation, enhancement,\n",
      "processing\n",
      "Data Visualization\n",
      "Natural language interfaces have contributed to generating visualizations\n",
      "directly from natural language, but visualization problems remain challenging\n",
      "due to the ambiguity of natural language.ChatGPT provides a new avenue for\n",
      "the \feld by converting natural language into visualized code.\n",
      "In terms of data visualization, Noever et al. [41] tested ChatGPT's ba-\n",
      "sic arithmetic skills by asking questions.On the iris dataset, Titanic survival\n",
      "dataset, Boston housing data, and randomly generated insurance claims dataset,\n",
      "the statistical analysis of data and visualization problems were converted to\n",
      "programming problems using Jupyter to verify ChatGPT's ability to generate\n",
      "python code to draw suitable graphs and analyze the data. The results show\n",
      "that ChatGPT can access structured and organized datasets to perform the\n",
      "four basic software operations required for databases: create, read, update, and\n",
      "delete, and generate suitable python code to plot graphs for descriptive statis-\n",
      "tics, variable correlation analysis, describing trends, and other data analysis\n",
      "operations.Maddigan et al. [47] proposed an end-to-end solution for visualizing\n",
      "data in natural language using LLM, which uses an open-source python frame-\n",
      "work designed to generate appropriate hints for selected datasets to make LLM\n",
      "more e\u000bective in understanding natural language, and uses internal reasoning\n",
      "capabilities to select the appropriate visualization type to generate the code for\n",
      "visualization. In this paper,the reseachers compare the visualization results of\n",
      "GPT-3, Codex and ChatGPT in the case of nvBench SQLite database [48] and\n",
      "the visualization results of energy production dataset in the study of ADVISor\n",
      "with NL4DV [49, 50].In addition to, they explore the ability to reason and hy-\n",
      "pothesize of the LLM on movie dataset [48] when the hints are insu\u000ecient or\n",
      "wrong .Experimental results show that LLM can e\u000bectively support the end-to-\n",
      "end generation of visualization results from natural language when supported\n",
      "by hints, providing an e\u000ecient, reliable and accurate solution to the natural\n",
      "language visualization problem.\n",
      "15Information Extraction\n",
      "The goal of information extraction is to extract speci\fc information from\n",
      "natural language text for structured representation, including three important\n",
      "subtasks such as entity relationship extraction, named entity recognition, and\n",
      "event extraction, which have wide applications in business, medical, and other\n",
      "\felds.\n",
      "In information extraction, Wei et al. [51] proposed ChatIE, a ChatGPT-\n",
      "based multi-round question-and-answer framework for information extraction.\n",
      "The framework decomposes a complex information extraction (IE) task into\n",
      "several parts, then combines the results of each round into a \fnal structured\n",
      "result. The entity association triple extraction, named entity recognition, and\n",
      "event extraction tasks were performed on six datasets NYT11-HRL, DuIE2.0\n",
      ", conllpp, MSR , DuEE1.0 [52, 53, 54, 55, 56], and ACE05 in both languages,\n",
      "comparing three metrics of precision, recall, and F1 score.These results sug-\n",
      "gest that on six widely used IE datasets, ChatIE improves performance by an\n",
      "average of 18.98% compared to the original ChatGPT without ChatIE, and out-\n",
      "performs the supervised models FCM and MultiR [57, 58] on the NYT11-HRL\n",
      "dataset.While the original ChatGPT cannot solve complex IE problems with\n",
      "original task instructions, and with this framework, successfully IE tasks were\n",
      "implemented on six datasets.Gao et al. [59] explored the feasibility and chal-\n",
      "lenges of ChatGPT for event extraction on the ACE2005 corpus, evaluating the\n",
      "performance of ChatGPT in long-tail and complex scenarios (texts containing\n",
      "multiple events) and comparing it with two task-speci\fc models, Text2Event\n",
      "and EEQA [60, 61].Then,they explored the impact of di\u000berent cues on perfor-\n",
      "mance of ChatGPT. The results show that the average performance of Chat-\n",
      "GPT in long-tail and complex scenarios is only 51.04% of that of task-speci\fc\n",
      "models such as EEQA. Continuous re\fnement of cues does not lead to consis-\n",
      "tent performance improvements, and ChatGPT is highly sensitive to di\u000berent\n",
      "cue styles.Tang et al. [62] proposed a new training paradigm that incorporates\n",
      "appropriate cues to guide ChatGPT to generate a variety of examples with dif-\n",
      "ferent sentence structures and language patterns and eliminate the resulting\n",
      "low-quality or duplicate samples for downstream tasks. Although compared to\n",
      "a soft model for a speci\fc healthcare tasks, ChatGPT underperforms in Named\n",
      "Entity Recognition (NER) and Relationship Extraction (RE) tasks , in the Gene\n",
      "Association Database (GAD) Release; EU-ADR corpus for the RE task , the\n",
      "innovative training framework was able to train local models, with F1 scores im-\n",
      "proving from 23.37% to 63.99% for the named entity recognition task and from\n",
      "75%, while alleviating privacy concerns and time-consuming data collection and\n",
      "annotation problems.He et al. [63] proposed a contextual learning framework\n",
      "ICL- D3IE. this framework introduces formatted presentation, continuously it-\n",
      "erates to update and improve the presentation, and then combines ChatGPT\n",
      "for text information extraction. In the paper, ICL-D3IE is compared with ex-\n",
      "isting pre-trained models such as LiLT,BROS (in-distribution (ID) setting and\n",
      "out-of-distribution (OOD) setting) on datasets (FUNSD, CORD, and SROIE\n",
      "[64, 65, 66]).These results show that the ICL-D3IE method in all datasets and\n",
      "settings except for the ID setting on CORD are superior to other methods,\n",
      "16with ICL-D3IE (GPT-3) F1 scores reaching 90.32% on FUNSD and97.88% on\n",
      "SROIE; in the out-of-distribution (OOD) setting, ICL-D3IE performs much\n",
      "better than previous pre-trained methods on all datasets.Polak et al. [67] pro-\n",
      "posed ChatExtract method - consisting of a set of engineering prompts applied\n",
      "to a conversational LLM - for automatic data extraction. In the experiment,\n",
      "they extracted a large number of sentences from hundreds of papers and ran-\n",
      "domly selected 100 sentences containing data and 100 sentences without data\n",
      "as test data. The results show that the accuracy and recall of LLM exceeded\n",
      "90% and may be comparable to human accuracy in many cases; in addition to\n",
      "this, the experiments were conducted under the condition of removing follow-up\n",
      "prompts and not keeping the conversation compared to previous experiments,\n",
      "respectively. The accuracy of deleting follow-up questions dropped to 80.2%\n",
      "and the recall rate dropped to 88.0%. Removing the conversational aspect and\n",
      "related information retention recall and accuracy dropped to 90.0% and 56.6%,\n",
      "respectively, demonstrating the e\u000bect of information retention combined with\n",
      "purposeful redundancy on LLM information extraction performance.\n",
      "Quality Assessment\n",
      "For translation quality, text generation quality, manual assessment is usually\n",
      "e\u000bective but su\u000bers from subjectivity and time-consuming, etc. It was found\n",
      "through exploration that ChatGPT has also achieved signi\fcant performance\n",
      "in automatic quality assessment.\n",
      "In terms of quality assessment,Kocmi et al. [68] proposed a GPT-based\n",
      "translation quality assessment metric, GEMBA, which evaluates the transla-\n",
      "tion of each fragment individually and then averages all the obtained scores to\n",
      "obtain a \fnal system-level score. In the MQM2022 test set (English-German,\n",
      "English-Russian, and Chinese-English) [69], a scoring task was performed with\n",
      "a classi\fcation task to compare the accuracy [70] and kendall tau scores [71] of\n",
      "seven GPT models under four cue templates.The results showed that GEMBA\n",
      "had the highest system-level accuracy of 88.0% compared to more than 10 au-\n",
      "tomatic metrics such as BLEU, and among the seven GPT models, ChatGPT\n",
      "accuracy is above 80%, in addition to, the best performance can be obtained in\n",
      "the least constrained template, demonstrating the potential of LLM for trans-\n",
      "lation quality assessment tasks, but the evaluation is only applicable at the\n",
      "system level and needs further improvement.Wang et al. [72] used ChatGPT\n",
      "as a natural language generation (NLG) evaluator to study the correlation with\n",
      "human judgment. On three datasets covering di\u000berent NLG tasks, task- and\n",
      "aspect-speci\fc cues were designed to guide ChatGPT for NLG evaluation in\n",
      "CNN/DM [73], OpenMEVA-ROC, and BAGEL for summary, story generation,\n",
      "and data-to-text scoring, respectively. Then,they compute Spearman coe\u000e-\n",
      "cients [74],Pearson correlation coe\u000ecients [75]. Kendall's Tau score [76] to as-\n",
      "sess the correlation with human evaluations.The results show that ChatGPT is\n",
      "highly correlated with human judgments in all aspects, with correlation coe\u000e-\n",
      "cients of 0.4 or more in all categories, showing its potential as an NLG indicator.\n",
      "17Data Augmentation\n",
      "In natural language processing, text data augmentation is an e\u000bective mea-\n",
      "sure to alleviate the problem of low data quantity and low quality training data,\n",
      "and ChatGPT has shown great potential in this regard.\n",
      "In terms of data augmentation, Dai et al. [77] proposed a ChatGPT-based\n",
      "text data augmentation method that reformulates each sentence in the train-\n",
      "ing sample into multiple conceptually similar but semantically di\u000berent samples\n",
      "for classi\fcation tasks downstream of the Bert model.On text transcriptions\n",
      "and PubMed 20k datasets containing more than 8 hours of audio data of com-\n",
      "mon medical symptom descriptions,experiments were conducted to compare co-\n",
      "sine similarity and TransRate metrics with multiple data enhancement methods\n",
      "[9].This paper shows that compared with existing data enhancement methods,\n",
      "the proposed ChatAug method shows a double-digit improvement in sentence\n",
      "classi\fcation accuracy and generates more diverse augmented samples while\n",
      "maintaining its accuracy, but the original model is not \fne-tuned in the pa-\n",
      "per and su\u000bers from a lack of domain knowledge, which may produce incorrect\n",
      "augmented data.\n",
      "Multimodal fusion\n",
      "ChatGPT can currently only process natural language directly, but with a\n",
      "cross-modal encoder, it can combine natural language with cross-modal pro-\n",
      "cessing to provide solutions for intelligent transportation, healthcare, and other\n",
      "\felds.\n",
      "In terms of multimodal data processing, Wu et al. [78] constructed a frame-\n",
      "work that Visual ChatGPT integrates with di\u000berent Visual Foundation Models\n",
      "(VFMs) and then combines a series of hints to input visual information to Chat-\n",
      "GPT to solve visual problems.The paper shows examples of visual tasks such\n",
      "as removing or replacing certain objects from images, interconversion between\n",
      "images and text, demonstrating the Visual ChatGPT has great potential and\n",
      "capability for di\u000berent tasks.But there are issues during the task that require\n",
      "a large number of hints to convert VFMs to language, invoke multiple VFMs\n",
      "to solve complex problems leading to limited real-time capability, and security\n",
      "and privacy issues. Zheng et al. [79] showed a text mining example of LLM\n",
      "for extracting self-driving car crash data from California crash news, analyz-\n",
      "ing a failure report example, and generating a crash report example based on\n",
      "keywords; introduced a use case concept of a smartphone-based framework for\n",
      "automatic LLM failure report generation, which absorbs multiple data sources\n",
      "captured by cell phone sensors and then transfers the data to a language space\n",
      "for text mining, inference and generation, and further outputs the key informa-\n",
      "tion needed to form a comprehensive fault report, demonstrating the potential\n",
      "of LLM for a variety of transportation tasks.\n",
      "Nowadays, ChatGPT shows a wide range of applications in data visualiza-\n",
      "tion, information extraction, data enhancement, quality assessment, and multi-\n",
      "modal data processing.But there are also issues on how to further utilize hints\n",
      "to e\u000bectively interact with ChatGPT, lack of ability to process and analyze data\n",
      "18from devices such as sensors, and data privacy and security.\n",
      "Cueing Techniques\n",
      "Cue engineering provides important support for e\u000bective dialogue with large\n",
      "language models.White et al. [80] proposed a framework for cueing models\n",
      "applicable to di\u000berent domains. This framework structures cues to interact\n",
      "with LLMs by providing speci\fc rules and guidelines. Also, this paper presents\n",
      "a catalog of cueing patterns that have been applied to LLM interactions, as well\n",
      "as speci\fc examples with and without cues. The advantages of the combinability\n",
      "of prompting patterns are demonstrated, allowing users to interact with LLM\n",
      "more e\u000bectively, but patterns for reusable solutions and new ways to use LLM\n",
      "need to be continuously explored.\n",
      "2.1.7 Human-ChatGPT Collaboration\n",
      "Collaboration between humans and machines is a process where humans and\n",
      "machines work together to achieve a common goal. In such collaboration, hu-\n",
      "mans provide domain expertise, creativity, and decision-making abilities, while\n",
      "machines provide automation, scalability, and computing power. ChatGPT is\n",
      "an advanced natural language processing model that can understand and gen-\n",
      "erate human-like language, thereby reducing communication costs. Its ability\n",
      "to process and generate natural language makes it an ideal partner for human\n",
      "collaboration. ChatGPT can o\u000ber relevant suggestions, complete tasks based\n",
      "on human input, and enhance human productivity and creativity. It can learn\n",
      "from human feedback and adapt to new tasks and domains, further improv-\n",
      "ing its performance in human-machine collaboration. ChatGPT's capability to\n",
      "comprehend natural language and produce appropriate responses makes it a\n",
      "valuable tool for various collaboration applications, as demonstrated by several\n",
      "studies in the literature we have gathered.\n",
      "Ahmad et al. [81] proposed a method for human-machine collaboration us-\n",
      "ing ChatGPT to create software architecture. This method transforms software\n",
      "stories (created by software architects based on application scenarios) into feasi-\n",
      "ble software architecture diagrams through continuous interaction between the\n",
      "software architect and ChatGPT. During the evaluation stage, ChatGPT uses\n",
      "the Software Architecture Analysis Method (SAAM) to evaluate each compo-\n",
      "nent in the software architecture and generate evaluation reports. This method\n",
      "e\u000eciently utilizes the knowledge and supervision of the architect with the ca-\n",
      "pabilities of ChatGPT to collaboratively build software-intensive systems and\n",
      "services. Lanzi et al. [82] proposed a collaborative design framework that com-\n",
      "bines interactive evolution and ChatGPT to simulate typical human design pro-\n",
      "cesses. Humans collaborate with large language models (such as ChatGPT) to\n",
      "recombine and transform ideas, and use genetic algorithms to iterate through\n",
      "complex creative tasks. The results of three game design tasks showed that the\n",
      "framework received positive feedback from game designers. The framework has\n",
      "good reusability and can be applied to any design task that can be described in\n",
      "free text form.\n",
      "19In the future, ChatGPT's ability to understand nonverbal cues such as tone\n",
      "of voice and body language can be enhanced, enabling it to better understand\n",
      "human thoughts and interact with people more e\u000bectively.\n",
      "2.1.8 ChatGPT Integration\n",
      "Integration refers to combining di\u000berent systems or software components to\n",
      "achieve a common goal. ChatGPT can be integrated as a part of a whole or\n",
      "act as an integration tool to enable seamless communication between di\u000berent\n",
      "systems. Its natural language processing ability makes it easier for non-technical\n",
      "users to interact with systems, reducing the need for specialized knowledge or\n",
      "training. Some studies in the literature we collected have already demonstrated\n",
      "this.\n",
      "Treude et al. [39] integrated ChatGPT into the prototype of \"GPTCOM-\n",
      "CARE\" to address programming query problems. This integration allowed for\n",
      "the generation of multiple source code solutions for the same query, which in-\n",
      "creased the e\u000eciency of software development. The results of their study demon-\n",
      "strated the e\u000bectiveness of using ChatGPT to improve the quality and diversity\n",
      "of code solutions, ultimately reducing the amount of time and e\u000bort required for\n",
      "software development.Wang et al. [83] proposed the chatCAD method, which\n",
      "utilizes large language models (LLMs) such as ChatGPT to enhance the out-\n",
      "put of multiple CAD networks for medical images, including diagnosis, lesion\n",
      "segmentation, and report generation networks. The method generates sugges-\n",
      "tions in the form of a chat dialogue. The authors tested the e\u000bectiveness of\n",
      "the method on a randomly selected set of 300 cases from the MIMIC-CXR\n",
      "dataset, which included 50 cases each of cardiomegaly, edema, consolidation,\n",
      "atelectasis, pleural e\u000busion, and no \fndings. Compared to CvT2DistilGPT2\n",
      "and R2GenCMN, chatCAD showed signi\fcant advantages in RC and F1, while\n",
      "only performing weaker than R2GenCMN in PR.\n",
      "Integrating ChatGPT into applications will still present challenges. Firstly,\n",
      "ChatGPT's performance may be a\u000bected by language barriers or di\u000berences\n",
      "in terminology between di\u000berent systems. Additionally, ChatGPT's responses\n",
      "are not always deterministic, which poses a challenge when integrating with\n",
      "systems that require precise and reproducible results. Finally, the processing\n",
      "time of ChatGPT is slow for integration tasks involving time-sensitive data such\n",
      "as tra\u000ec, which is a limitation in time-critical environments.\n",
      "2.2 AI Ethics\n",
      "Since the advent of ChatGPT, this powerful natural language processing model\n",
      "has not only brought great convenience to people but also triggered more crisis-\n",
      "aware thinking. Some researchers have started to hypothesize and study the\n",
      "potential negative impacts of ChatGPT. This proactive research provides good\n",
      "proposals for standardized construction to address future AI abuse issues.\n",
      "Regarding the evaluation of ChatGPT's own political and ethical tendencies,\n",
      "Hartmann et al. [84] used Wahl-O-Mat, one of the most commonly used voting\n",
      "20advice applications in the world, to show ChatGPT political statements from\n",
      "di\u000berent parties, forcing it to make choices of agree, disagree, or neutral. The\n",
      "results indicated that ChatGPT has a pro-environment, left-wing liberal ide-\n",
      "ology, which was also con\frmed in the nation-state agnostic political compass\n",
      "test. Another study (referenced as [85]) examined ChatGPT's moral standards\n",
      "by repeatedly asking it di\u000berent versions of the trolley problem, and found that\n",
      "ChatGPT gave answers with di\u000berent moral orientations, lacking a \frm moral\n",
      "stance. A subsequent test also found that ChatGPT's lack of consistency could\n",
      "a\u000bect people's moral judgments. Additionally, Borji et al. [86] demonstrated\n",
      "ChatGPT's inconsistency in reasoning, factual errors, mathematics, coding, and\n",
      "bias across eleven related aspects. These \fndings highlight ChatGPT's inher-\n",
      "ent traits and limitations, and people should be aware of their potential impact\n",
      "when seeking advice from ChatGPT.\n",
      "Regarding relevant policies and regulations, Hacker et al. [87] discussed the\n",
      "nature and rules of large generative AI models, including ChatGPT, which are\n",
      "rapidly changing the way we communicate, explain, and create. The author\n",
      "suggested that di\u000berent stakeholders in the value chain should take regulatory\n",
      "responsibility and deploy four strategies to tailor more comprehensive laws for\n",
      "the bene\ft of society. Another study (referenced as [88]) criticized the European\n",
      "Commission's proposal on AI responsibility and suggested revising the proposed\n",
      "AI responsibility framework to ensure e\u000bective compensation while promoting\n",
      "innovation, legal certainty, and sustainable AI regulation. A policy framework\n",
      "was proposed (referenced as [89]) to customize LLMs, such as ChatGPT, in a so-\n",
      "cially acceptable and safe manner, emphasizing the need to align large language\n",
      "models (LLMs) with human preferences.\n",
      "uence users' be-d ethical tendencies of ChatGPT could in\n",
      "havior and decision-making to some extent. However, some studies have con-\n",
      "ducted in-depth research on the use of norms and limitations, which could enable\n",
      "humans to use ChatGPT more reasonably and safely.\n",
      "2.3 Evaluation\n",
      "2.3.1 Comparison of ChatGPT with existing popular models\n",
      "We use publicly available datasets to comprehensively evaluate the strengths\n",
      "and limitations of ChatGPT. Reference [90] evaluates the technical performance\n",
      "of ChatGPT in multitask, multilingual, and multimodal aspects based on 23\n",
      "standard public datasets and newly designed multimodal datasets, including\n",
      "eight di\u000berent common natural language processing application tasks. The ex-\n",
      "perimental results show that, in terms of multitasking, ChatGPT outperforms\n",
      "various state-of-the-art zero-shot learning large language models in most tasks,\n",
      "and even outperforms \fne-tuned task-speci\fc models in some individual tasks.\n",
      "In terms of multilingualism, we found that ChatGPT cannot be applied to low-\n",
      "resource languages because it cannot understand the language and generate\n",
      "translations for that language. In terms of multimodality, ChatGPT's ability is\n",
      "still basic compared to specialized language-visual models.\n",
      "21In terms of stability, reference [91] concludes that ChatGPT's performance is\n",
      "always lower than SOTA, the current state-of-the-art model, in almost all tasks.\n",
      "This means that as a general model, ChatGPT has never reached the level of the\n",
      "best existing models. Experimental data shows that the average quality of the\n",
      "SOTA model is 73.7%, while the average quality of the ChatGPT model is only\n",
      "56.5%. At the same time, ChatGPT's stability is poor: the standard deviation\n",
      "of its performance is 23.3%, while the SOTA model's standard deviation is\n",
      "only 16.7%. This non-deterministic behavior exhibited by ChatGPT could be\n",
      "a serious drawback in some problems.\n",
      "Similarly, Qin et al. [92] conducted a comprehensive evaluation of whether\n",
      "ChatGPT is a quali\fed general natural language processing task solver. The ex-\n",
      "periment analyzed ChatGPT's zero-shot learning ability based on 20 commonly\n",
      "used public datasets covering 7 representative task categories. Below, we will\n",
      "analyze ChatGPT's performance on each task:\n",
      "In terms of reasoning tasks, ChatGPT performs average on mathematical\n",
      "symbol, commonsense causal, and logical reasoning tasks, but performs well\n",
      "in arithmetic reasoning [92]. That is to say, ChatGPT's abilities vary among\n",
      "di\u000berent types of reasoning tasks. In terms of logical reasoning, ChatGPT's\n",
      "deductive and abductive reasoning are superior to inductive reasoning, while\n",
      "in other reasoning tasks, such as analogy, causal and commonsense reasoning,\n",
      "ChatGPT performs well [90].\n",
      "In terms of sentiment analysis task, ChatGPT performs similarly to GPT-3.5\n",
      "and bert-style models [92, 93]. However, according to literature [91], ChatGPT\n",
      "has losses not exceeding 25% on most tasks, except for three relatively sub-\n",
      "jective emotion perception tasks where it performs poorly. If we remove these\n",
      "tasks to calculate the average quality of the two models, we \fnd that the SOTA\n",
      "method has an average quality of 80%, while the ChatGPT method has an av-\n",
      "erage quality of 69.7%. That is to say, ChatGPT performs well on all tasks\n",
      "except for emotion-related tasks, and can handle most of the problems we con-\n",
      "sider. However, overall, its performance is lower than the SOTA model based\n",
      "on experimental data, but the di\u000berence between the two is not very large.\n",
      "In other tasks, according to literature [92], ChatGPT performs well in nat-\n",
      "ural language inference, i.e., the task of inferring sentence relationships, and its\n",
      "performance on this task is signi\fcantly better than all bert-style models [93].\n",
      "However, while ChatGPT performs well on inference tasks, it may produce some\n",
      "self-contradictory or unreasonable responses, which is its potential limitation.\n",
      "In question-answering, dialogue, and summarization tasks, ChatGPT performs\n",
      "better than the GPT-3.5 model [92], especially in the question-answering task,\n",
      "where its performance is comparable to bert-style models [93]. Therefore, we\n",
      "have demonstrated that ChatGPT is a quali\fed general-purpose model.\n",
      "However, ChatGPT also has limitations in many aspects. Firstly, it lacks the\n",
      "ability to handle non-textual semantic reasoning tasks such as mathematical,\n",
      "temporal, and spatial reasoning, and it performs poorly in multi-hop reasoning\n",
      "[90]. Secondly, ChatGPT is not good at solving named entity recognition tasks\n",
      "[92]. Furthermore, ChatGPT performs poorly in handling tasks involving nega-\n",
      "tive connotations and neutral similarity [93]. Finally, these conclusions indicate\n",
      "22that, like other large pre-trained language models, ChatGPT has limitations in\n",
      "completing complex reasoning tasks.\n",
      "In summary, ChatGPT's zero-shot performance is comparable to \fne-tuned\n",
      "bert and GPT-3.5 models, and with the help of advanced prompting strategies,\n",
      "ChatGPT can demonstrate better comprehension abilities. However, it still\n",
      "cannot outperform the current SOTA models.\n",
      "2.3.2 The possibility of using ChatGPT for plagiarism and cheating\n",
      "In response to the possibility of ChatGPT being used for plagiarism and cheat-\n",
      "ected on the current state of development of arti\fcial in-\n",
      "telligence like ChatGPT. As ChatGPT becomes increasingly easy to obtain and\n",
      "scalable in text generation, there is a high likelihood that these technologies will\n",
      "be used for plagiarism, including scienti\fc literature and news sources, posing\n",
      "a great threat to the credibility of various forms of news media and academic\n",
      "articles. Some scholars are concerned that the end of paper as a meaningful\n",
      "evaluation tool may be approaching [95, 96], as ChatGPT can easily generate\n",
      "persuasive paragraphs, chapters, and papers on any given topic. Additionally,\n",
      "it will exacerbate plagiarism issues in many \felds such as education, medicine,\n",
      "and law [10], and may be used for cheating in academic exams [97]. De\fnitional\n",
      "recognition technology is a relatively e\u000bective method for detecting plagiarism,\n",
      "and the de\fnitional typology proposed in [94] can alleviate people's concerns by\n",
      "being used to construct new datasets. Susnjak [97] proposed a solution to the\n",
      "possibility of large language models like ChatGPT being used for exam cheat-\n",
      "ing: guiding ChatGPT to generate some critical thinking problems through\n",
      "questioning, then providing answers and critically evaluating them. Analysis of\n",
      "ChatGPT shows that it exhibits critical thinking, can generate highly realistic\n",
      "text in terms of accuracy, relevance, depth, breadth, logic, persuasiveness, and\n",
      "originality. Therefore, educators must be aware of the possibility of ChatGPT\n",
      "being used for exam cheating and take measures to combat cheating behavior\n",
      "to ensure the fairness of online exams.\n",
      "2.3.3 Feedback from ChatGPT users\n",
      "In response to feedback from ChatGPT users, Haque et al. [98] conducted a\n",
      "mixed-methods study using 10,732 early ChatGPT user tweets. The authors\n",
      "extracted Twitter data using Python and Twitter API and constructed the\n",
      "ChatGPTTweet dataset, which contains 18k tweets. For each tweet, the au-\n",
      "thors collected information on text content, user location, occupation, veri\fca-\n",
      "tion status, date of publication, and tags. Based on this dataset, the authors\n",
      "studied the characteristics of early ChatGPT users, discussion topics related to\n",
      "ChatGPT on Twitter, and the sentiment of Twitter users toward ChatGPT.\n",
      "For RQ1, the authors found that early ChatGPT users had a diverse and wide\n",
      "range of occupational backgrounds and geographical locations. For RQ2, the\n",
      "authors identi\fed nine topics related to ChatGPT, including its impact on soft-\n",
      "ware development, entertainment and creativity, natural language processing,\n",
      "23education, chatbot intelligence, business development, search engines, question-\n",
      "answering tests, and future careers and opportunities. For RQ3, most early\n",
      "users expressed positive sentiment toward topics such as software development\n",
      "and creativity, while only a few expressed concern about the potential misuse\n",
      "of ChatGPT.\n",
      "2.3.4 Adverse e\u000bects of ChatGPT on users\n",
      "Regarding the negative e\u000bects of ChatGPT on users, Luan et al. [99] studied\n",
      "the psychological principles of ChatGPT, delved into the factors that attract\n",
      "users' attention, and revealed the impact of these factors on future learning.\n",
      "In the post-pandemic era, teachers and students are both facing uncertainty\n",
      "in the teaching process and job pressures. Under these common constraints of\n",
      "education and employment, educators and students must re-evaluate current\n",
      "educational methods and outcomes, as well as students' future career devel-\n",
      "opment. Through question-and-answer exchanges with ChatGPT, people can\n",
      "easily obtain appropriate solutions or key information, thereby enhancing their\n",
      "motivation, eliminating anxiety in learning, improving interest, and achieving\n",
      "psychological satisfaction. Subhash et al. [100] explored whether large language\n",
      "models have the ability to reverse user preferences. With the development of\n",
      "pre-trained large language models, people are increasingly concerned about the\n",
      "uence, persuade, and potentially manipulate user\n",
      "preferences in extreme cases. Therefore, the literature [100] roughly qualita-\n",
      "tively analyzed that adversarial behavior does lead to potential changes in user\n",
      "preferences and behaviors in dialogue systems. If we want to further quanti-\n",
      "tatively analyze the ability of large language models in this regard, additional\n",
      "statistical summary techniques need to be used for future research.\n",
      "3 Discussion\n",
      "3.1 Limitations\n",
      "Despite the remarkable capabilities of ChatGPT and GPT-4, it still faces certain\n",
      "limitations. Some of these limitations include:\n",
      "Outdated Knowledge\n",
      "The current models are trained on historical data (up to 2021), thereby\n",
      "lacking real-time comprehension of current a\u000bairs. This is a critical concern\n",
      "in today's information-explosion era, as the reliability of prior knowledge bases\n",
      "progressively diminishes, potentially yielding inaccurate responses, especially in\n",
      "rapidly evolving domains such as jurisprudence and technology. Additionally,\n",
      "these models are incapable of fact-checking while the training data is composed\n",
      "of content from various sources, some of which may be unreliable, which may\n",
      "result in seemingly plausible yet nonsensical responses.\n",
      "24Insu\u000ecient Understanding\n",
      "While these models can interpret the majority of inquiries and contextual\n",
      "situations, they occasionally encounter comprehension biases when addressing\n",
      "ambiguous or contextually complex queries. Furthermore, in certain specialized\n",
      "\felds, the abundance of unique abbreviation exacerbates the models' under-\n",
      "standing challenges, resulting in incorrect and vacuous responses.\n",
      "Energy Consumption\n",
      "Throughout the training and inference stages, these large-scale models re-\n",
      "quire signi\fcant computational resources and electrical power, resulting in ele-\n",
      "vated energy consumption and signi\fcant carbon emissions. Consequently, this\n",
      "restricts their deployment and practical applications.\n",
      "Malicious Usage\n",
      "Despite OpenAI implementing a series of restrictions to mitigate model tox-\n",
      "icity, instances of users evading these constraints through meticulously designed\n",
      "prompts have emerged, inducing the model to produce unhealthy content or\n",
      "even using it for illicit commercial purposes.\n",
      "Bias and Discrimination\n",
      "uence of pre-training data, the models exhibit biases in polit-\n",
      "ical, ideological, and other areas. The application of LLMs in public domains,\n",
      "such as education and publicity, should be approached with extreme caution.\n",
      "Privacy and Data Security\n",
      "Concurrent with the expansion of users, protecting user privacy and data\n",
      "security becomes increasingly important. In fact, ChatGPT was banned in\n",
      "Italy in early April due to privacy concerns. This is particularly relevant given\n",
      "the models' extensive collection of personal information and preferences during\n",
      "interactions, and as future multimodal models, such as GPT-4, may frequently\n",
      "require users to upload private photos.\n",
      "3.2 Future Directions\n",
      "In forthcoming research, the development of models based on ChatGPT and\n",
      "GPT-4 may focus on addressing these limitations to enhance their practical\n",
      "applications.\n",
      "Primarily, researchers should continue to work on re\fning model training\n",
      "methodologies while \fltering pre-training data to minimize the presence of mis-\n",
      "leading information in the model's knowledge base, thereby obtaining accurate\n",
      "responses. Concurrently, it is crucial to emphasize training approaches that\n",
      "economize computational resources, thereby mitigating costs and broadening\n",
      "potential application scenarios.\n",
      "Moreover, the advancements in context-awareness and disambiguation tech-\n",
      "nologies are anticipated to facilitate enhanced comprehension of complex queries\n",
      "25by models, improving the accuracy, relevance, and context-awareness of AI-\n",
      "generated content. Integrating real-time data streams can also keep these mod-\n",
      "els in sync with current events and trends, enabling them to provide up-to-date\n",
      "information such as live tra\u000ec, weather, and stock updates.\n",
      "Additionally, developers should engage in interdisciplinary collaboration with\n",
      "specialists from diverse domains, including policy-making, jurisprudence, and\n",
      "sociology, with the objective of formulating standard and ethical frameworks\n",
      "for LLM development, deployment, and utilization, thereby alleviating poten-\n",
      "tial harmful consequences. In terms of public awareness and education, manda-\n",
      "tory awareness training should be implemented prior to large-scale public de-\n",
      "ployment and application to increase public awareness of LLM capabilities and\n",
      "limitations while promoting responsible and informed utilization, especially in\n",
      "industries such as K-12 education and journalism.\n",
      "uence of ChatGPT and GPT-4 should not be limited to\n",
      "just the NLP \feld. They also show promising prospects in the areas of com-\n",
      "puter vision, brain-inspired AI, and robotics. These models exhibit a capacity\n",
      "for learning and comprehension comparable with human-level intelligence, po-\n",
      "sitioning them as a pivotal component in the development of arti\fcial general\n",
      "intelligence (AGI)[101]. Their ability to facilitate seamless interactions between\n",
      "humans and robots paves the way for the execution of more complex tasks.\n",
      "The remarkable capacity of zero-shot in-context learning of these models en-\n",
      "ables quick adaptation to new tasks without the requirement for labeled data\n",
      "for \fne-tuning, which is a critical challenge in \felds like medical informatics[102]\n",
      "and robotics[103] where the availability of labeled data is commonly limited or\n",
      "non-existent.\n",
      "4 Conclusion\n",
      "This review paper provides a comprehensive survey of ChatGPT and GPT-4,\n",
      "highlighting their potential applications and signi\fcant contributions to the \feld\n",
      "of natural language processing. The \fndings of this study reveal that the interest\n",
      "in these models is growing rapidly, and they have shown considerable potential\n",
      "for application across a wide range of domains. One key factor contributing\n",
      "to the success of ChatGPT and GPT-4 is their ability to perform large-scale\n",
      "pre-training, which captures knowledge from the vast expanse of the internet,\n",
      "allowing the models to learn from a massive amount of data. The integration of\n",
      "Reinforcement Learning from Human Feedback (RLHF) has further enhanced\n",
      "the model's adaptability and performance, making it highly e\u000ecient in process-\n",
      "ing natural language. This study has also identi\fed several potential ethical\n",
      "concerns related to the development and use of ChatGPT and GPT-4. For in-\n",
      "stance, there are concerns about the generation of biased or harmful content,\n",
      "privacy violations, and the potential for misuse of the technology. It is crucial\n",
      "to address these concerns and ensure that ChatGPT and GPT-4 are developed\n",
      "and used in a responsible and ethical manner. Furthermore, the results of this\n",
      "study demonstrate that there is signi\fcant potential for ChatGPT and GPT-4\n",
      "26to be applied in a range of domains, including education, history, mathematics,\n",
      "physics, and more. These models can facilitate tasks such as generating sum-\n",
      "maries, answering questions, and providing personalized recommendations to\n",
      "users. Overall, the insights presented in this review paper can serve as a useful\n",
      "guide for researchers and practitioners looking to advance the \feld of natural\n",
      "language processing. Future research in this \feld should focus on addressing\n",
      "ethical concerns, exploring new applications, and ensuring the responsible use\n",
      "of ChatGPT and GPT-4. The potential of these models to revolutionize natural\n",
      "language processing is enormous, and we look forward to seeing more develop-\n",
      "ments in this \feld.\n",
      "References\n",
      "[1] Radford A, Narasimhan K, Salimans T, Sutskever I, et al. Improving\n",
      "language understanding by generative pre-training. OpenAI. 2018.\n",
      "[2] Radford A, Wu J, Child R, Luan D, Amodei D, Sutskever I, et al.\n",
      "Language models are unsupervised multitask learners. OpenAI blog.\n",
      "2019;1(8):9.\n",
      "[3] Radford A, Wu J, Amodei D, Amodei D, Clark J, Brundage M, et al. Bet-\n",
      "ter language models and their implications. OpenAI Blog https://openai\n",
      "com/blog/better-language-models. 2019;1(2).\n",
      "[4] Brown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P, et al.\n",
      "Language models are few-shot learners. Advances in neural information\n",
      "processing systems. 2020;33:1877-901.\n",
      "[5] Ouyang L, Wu J, Jiang X, Almeida D, Wainwright CL, Mishkin P, et al.\n",
      "Training language models to follow instructions with human feedback.\n",
      "arXiv preprint arXiv:220302155. 2022.\n",
      "[6] Christiano PF, Leike J, Brown T, Martic M, Legg S, Amodei D. Deep\n",
      "reinforcement learning from human preferences. Advances in neural infor-\n",
      "mation processing systems. 2017;30.\n",
      "[7] Frieder S, Pinchetti L, Gri\u000eths RR, Salvatori T, Lukasiewicz T, Pe-\n",
      "tersen PC, et al. Mathematical capabilities of chatgpt. arXiv preprint\n",
      "arXiv:230113867. 2023.\n",
      "[8] Pardos ZA, Bhandari S. Learning gain di\u000berences between ChatGPT and\n",
      "human tutor generated algebra hints. arXiv preprint arXiv:230206871.\n",
      "2023.\n",
      "[9] Shakarian P, Koyyalamudi A, Ngu N, Mareedu L. An Independent Eval-\n",
      "uation of ChatGPT on Mathematical Word Problems (MWP). arXiv\n",
      "preprint arXiv:230213814. 2023.\n",
      "27[10] Lehnert K. AI Insights into Theoretical Physics and the Swampland Pro-\n",
      "gram: A Journey Through the Cosmos with ChatGPT. arXiv preprint\n",
      "arXiv:230108155. 2023.\n",
      "[11] Kortemeyer G. Could an Arti\fcial-Intelligence agent pass an introductory\n",
      "physics course? arXiv preprint arXiv:230112127. 2023.\n",
      "[12] West CG. AI and the FCI: Can ChatGPT Project an Understanding of\n",
      "Introductory Physics? arXiv preprint arXiv:230301067. 2023.\n",
      "[13] Nov O, Singh N, Mann DM. Putting ChatGPT's Medical Advice to the\n",
      "(Turing) Test. medRxiv. 2023.\n",
      "[14] Tu R, Ma C, Zhang C. Causal-Discovery Performance of ChatGPT in the\n",
      "context of Neuropathic Pain Diagnosis. arXiv preprint arXiv:230113819.\n",
      "2023.\n",
      "[15] Glymour C, Zhang K, Spirtes P. Review of Causal Discovery Methods\n",
      "Based on Graphical Models. Frontiers in Genetics. 2019.\n",
      "[16] Guo S, Wang Y, Li S, Saeed N. Semantic Communications with Ordered\n",
      "Importance using ChatGPT. arXiv preprint arXiv:230207142. 2023.\n",
      "[17] Wang S, Scells H, Koopman B, Zuccon G. Can chatgpt write a good\n",
      "boolean query for systematic review literature search? arXiv preprint\n",
      "arXiv:230203495. 2023.\n",
      "[18] Kuzman T, Mozetic I, Ljube\u0014 sic N. ChatGPT: Beginning of an End of\n",
      "Manual Linguistic Data Annotation? Use Case of Automatic Genre Iden-\n",
      "ti\fcation. arXiv e-prints. 2023:arXiv-2303.\n",
      "[19] Amin MM, Cambria E, Schuller BW. Will A\u000bective Computing Emerge\n",
      "from Foundation Models and General AI? A First Evaluation on Chat-\n",
      "GPT. arXiv preprint arXiv:230303186. 2023.\n",
      "[20] Zhang B, Ding D, Jing L. How would Stance Detection Techniques Evolve\n",
      "after the Launch of ChatGPT? arXiv preprint arXiv:221214548. 2022.\n",
      "[21] Huang F, Kwak H, An J. Is ChatGPT better than Human Annota-\n",
      "tors? Potential and Limitations of ChatGPT in Explaining Implicit Hate\n",
      "Speech. arXiv preprint arXiv:230207736. 2023.\n",
      "[22] Zhang X, Chowdhury RR, Hong D, Gupta RK, Shang J. Model-\n",
      "ing Label Semantics Improves Activity Recognition. arXiv preprint\n",
      "arXiv:230103462. 2023.\n",
      "[23] Fu Q, Teng Z, Georgaklis M, White J, Schmidt DC. NL2CMD: An Up-\n",
      "ow for Natural Language to Bash Commands Translation.\n",
      "arXiv preprint arXiv:230207845. 2023.\n",
      "28[24] Chen Y, Eger S. Transformers go for the LOLs: Generating (humourous)\n",
      "titles from scienti\fc abstracts end-to-end. arXiv preprint arXiv:221210522.\n",
      "2022.\n",
      "[25] Chen N, Wang Y, Jiang H, Cai D, Chen Z, Li J. What would Harry\n",
      "say? Building Dialogue Agents for Characters in a Story. arXiv preprint\n",
      "arXiv:221106869. 2022.\n",
      "[26] Jeblick K, Schachtner B, Dexl J, Mittermeier A, St uber AT, Topalis J,\n",
      "et al. ChatGPT Makes Medicine Easy to Swallow: An Exploratory Case\n",
      "Study on Simpli\fed Radiology Reports. arXiv preprint arXiv:221214882.\n",
      "2022.\n",
      "[27] Xia CS, Zhang L. Conversational automated program repair. arXiv\n",
      "preprint arXiv:230113246. 2023.\n",
      "[28] Jiao W, ZhaopengTu WJtX. Is ChatGPT A Good Translator? Yes With\n",
      "GPT-4 As The Engine.\n",
      "[29] Prieto SA, Mengiste ET, de Soto BG. Investigating the Use of\n",
      "ChatGPT for the Scheduling of Construction Projects. Buildings.\n",
      "2023 mar;13(4):857. Available from: https://doi.org/10.3390%\n",
      "2Fbuildings13040857 .\n",
      "[30] Michail A, Konstantinou S, Clematide S. UZH CLyp at SemEval-2023\n",
      "Task 9: Head-First Fine-Tuning and ChatGPT Data Generation for\n",
      "Cross-Lingual Learning in Tweet Intimacy Prediction. arXiv preprint\n",
      "arXiv:230301194. 2023.\n",
      "[31] Wang J, Liang Y, Meng F, Li Z, Qu J, Zhou J. Cross-Lingual Summa-\n",
      "rization via ChatGPT. arXiv preprint arXiv:230214229. 2023.\n",
      "[32] Yang X, Li Y, Zhang X, Chen H, Cheng W. Exploring the limits of\n",
      "chatgpt for query or aspect-based text summarization. arXiv preprint\n",
      "arXiv:230208081. 2023.\n",
      "[33] Belouadi J, Eger S. ByGPT5: End-to-End Style-conditioned Po-\n",
      "etry Generation with Token-free Language Models. arXiv preprint\n",
      "arXiv:221210474. 2022.\n",
      "[34] Blanco-Gonzalez A, Cabezon A, Seco-Gonzalez A, Conde-Torres D,\n",
      "Antelo-Riveiro P, Pineiro A, et al. The Role of AI in Drug Discovery: Chal-\n",
      "lenges, Opportunities, and Strategies. arXiv preprint arXiv:221208104.\n",
      "2022.\n",
      "[35] Khalil M, Er E. Will ChatGPT get you caught? Rethinking of plagiarism\n",
      "detection. arXiv preprint arXiv:230204335. 2023.\n",
      "[36] Basic Z, Banovac A, Kruzic I, Jerkovic I. Better by you, better than\n",
      "me, chatgpt3 as writing assistance in students essays. arXiv preprint\n",
      "arXiv:230204536. 2023.\n",
      "29[37] Noever D, Ciolino M. The Turing Deception. arXiv preprint\n",
      "arXiv:221206721. 2022.\n",
      "[38] Megahed FM, Chen YJ, Ferris JA, Knoth S, Jones-Farmer LA. How\n",
      "Generative AI models such as ChatGPT can be (Mis) Used in SPC Prac-\n",
      "tice, Education, and Research? An Exploratory Study. arXiv preprint\n",
      "arXiv:230210916. 2023.\n",
      "[39] Treude C. Navigating Complexity in Software Engineering: A Prototype\n",
      "for Comparing GPT-n Solutions. arXiv preprint arXiv:230112169. 2023.\n",
      "[40] Sobania D, Briesch M, Hanna C, Petke J. An analysis of the automatic\n",
      "bug \fxing performance of chatgpt. arXiv preprint arXiv:230108653. 2023.\n",
      "[41] Noever D, McKee F. Numeracy from Literacy: Data Science as an Emer-\n",
      "gent Skill from Large Language Models. arXiv preprint arXiv:230113382.\n",
      "2023.\n",
      "[42] McKee F, Noever D. Chatbots in a Botnet World. arXiv preprint\n",
      "arXiv:221211126. 2022.\n",
      "[43] McKee F, Noever D. Chatbots in a Honeypot World. arXiv preprint\n",
      "arXiv:230103771. 2023.\n",
      "[44] Susnjak T. Applying BERT and ChatGPT for Sentiment Analysis of\n",
      "Lyme Disease in Scienti\fc Literature. arXiv preprint arXiv:230206474.\n",
      "2023.\n",
      "[45] Tang Z, Kejriwal M. A Pilot Evaluation of ChatGPT and DALL-E 2 on\n",
      "Decision Making and Spatial Reasoning. arXiv preprint arXiv:230209068.\n",
      "2023.\n",
      "[46] Ortega-Mart\u0013 \u0010n M, Garc\u0013 \u0010a-Sierra \u0013O, Ardoiz A, \u0013Alvarez J, Armenteros JC,\n",
      "Alonso A. Linguistic ambiguity analysis in ChatGPT. arXiv preprint\n",
      "arXiv:230206426. 2023.\n",
      "[47] Maddigan P, Susnjak T. Chat2vis: Generating data visualisations via\n",
      "natural language using chatgpt, codex and gpt-3 large language models.\n",
      "arXiv preprint arXiv:230202094. 2023.\n",
      "[48] Luo Y, Tang J, Li G. nvBench: A Large-Scale Synthesized Dataset for\n",
      "Cross-Domain Natural Language to Visualization Task. arXiv preprint\n",
      "arXiv:211212926. 2021.\n",
      "[49] Liu C, Han Y, Jiang R, Yuan X. Advisor: Automatic visualization answer\n",
      "for natural-language question on tabular data. In: 2021 IEEE 14th Paci\fc\n",
      "Visualization Symposium (Paci\fcVis). IEEE; 2021. p. 11-20.\n",
      "30[50] Narechania A, Srinivasan A, Stasko J. NL4DV: A toolkit for generat-\n",
      "ing analytic speci\fcations for data visualization from natural language\n",
      "queries. IEEE Transactions on Visualization and Computer Graphics.\n",
      "2020;27(2):369-79.\n",
      "[51] Wei X, Cui X, Cheng N, Wang X, Zhang X, Huang S, et al. Zero-\n",
      "Shot Information Extraction via Chatting with ChatGPT. arXiv preprint\n",
      "arXiv:230210205. 2023.\n",
      "[52] Takanobu R, Zhang T, Liu J, Huang M. A hierarchical framework for\n",
      "relation extraction with reinforcement learning. In: Proceedings of the\n",
      "AAAI conference on arti\fcial intelligence. vol. 33; 2019. p. 7072-9.\n",
      "[53] Li S, He W, Shi Y, Jiang W, Liang H, Jiang Y, et al. Duie: A large-\n",
      "scale chinese dataset for information extraction. In: Natural Language\n",
      "Processing and Chinese Computing: 8th CCF International Conference,\n",
      "NLPCC 2019, Dunhuang, China, October 9{14, 2019, Proceedings, Part\n",
      "II 8. Springer; 2019. p. 791-800.\n",
      "[54] Wang Z, Shang J, Liu L, Lu L, Liu J, Han J. Crossweigh: Training named\n",
      "entity tagger from imperfect annotations. arXiv preprint arXiv:190901441.\n",
      "2019.\n",
      "[55] Levow GA. The third international Chinese language processing bakeo\u000b:\n",
      "Word segmentation and named entity recognition. In: Proceedings of the\n",
      "Fifth SIGHAN workshop on Chinese language processing; 2006. p. 108-17.\n",
      "[56] Li X, Li F, Pan L, Chen Y, Peng W, Wang Q, et al. DuEE: a large-scale\n",
      "dataset for Chinese event extraction in real-world scenarios. In: Natu-\n",
      "ral Language Processing and Chinese Computing: 9th CCF International\n",
      "Conference, NLPCC 2020, Zhengzhou, China, October 14{18, 2020, Pro-\n",
      "ceedings, Part II 9. Springer; 2020. p. 534-45.\n",
      "[57] Gormley MR, Yu M, Dredze M. Improved relation extraction with feature-\n",
      "rich compositional embedding models. arXiv preprint arXiv:150502419.\n",
      "2015.\n",
      "[58] Ho\u000bmann R, Zhang C, Ling X, Zettlemoyer L, Weld DS. Knowledge-based\n",
      "weak supervision for information extraction of overlapping relations. In:\n",
      "Proceedings of the 49th annual meeting of the association for computa-\n",
      "tional linguistics: human language technologies; 2011. p. 541-50.\n",
      "[59] Gao J, Zhao H, Yu C, Xu R. Exploring the feasibility of ChatGPT for\n",
      "event extraction. arXiv preprint arXiv:230303836. 2023.\n",
      "[60] Lu Y, Lin H, Xu J, Han X, Tang J, Li A, et al. Text2event: Controllable\n",
      "sequence-to-structure generation for end-to-end event extraction. arXiv\n",
      "preprint arXiv:210609232. 2021.\n",
      "31[61] Du X, Cardie C. Event extraction by answering (almost) natural ques-\n",
      "tions. arXiv preprint arXiv:200413625. 2020.\n",
      "[62] Tang R, Han X, Jiang X, Hu X. Does Synthetic Data Generation of LLMs\n",
      "Help Clinical Text Mining? arXiv preprint arXiv:230304360. 2023.\n",
      "[63] He J, Wang L, Hu Y, Liu N, Liu H, Xu X, et al. ICL-D3IE: In-Context\n",
      "Learning with Diverse Demonstrations Updating for Document Informa-\n",
      "tion Extraction. arXiv preprint arXiv:230305063. 2023.\n",
      "[64] Jaume G, Ekenel HK, Thiran JP. Funsd: A dataset for form under-\n",
      "standing in noisy scanned documents. In: 2019 International Conference\n",
      "on Document Analysis and Recognition Workshops (ICDARW). vol. 2.\n",
      "IEEE; 2019. p. 1-6.\n",
      "[65] Park S, Shin S, Lee B, Lee J, Surh J, Seo M, et al. CORD: a consoli-\n",
      "dated receipt dataset for post-OCR parsing. In: Workshop on Document\n",
      "Intelligence at NeurIPS 2019; 2019. .\n",
      "[66] Huang Z, Chen K, He J, Bai X, Karatzas D, Lu S, et al. Icdar2019 com-\n",
      "petition on scanned receipt ocr and information extraction. In: 2019 In-\n",
      "ternational Conference on Document Analysis and Recognition (ICDAR).\n",
      "IEEE; 2019. p. 1516-20.\n",
      "[67] Polak MP, Morgan D. Extracting Accurate Materials Data from Research\n",
      "Papers with Conversational Language Models and Prompt Engineering{\n",
      "Example of ChatGPT. arXiv preprint arXiv:230305352. 2023.\n",
      "[68] Kocmi T, Federmann C. Large language models are state-of-the-art eval-\n",
      "uators of translation quality. arXiv preprint arXiv:230214520. 2023.\n",
      "[69] Freitag M, Rei R, Mathur N, Lo Ck, Stewart C, Avramidis E, et al.\n",
      "Results of WMT22 metrics shared task: Stop using BLEU{neural metrics\n",
      "are better and more robust. In: Proceedings of the Seventh Conference\n",
      "on Machine Translation (WMT); 2022. p. 46-68.\n",
      "[70] Kocmi T, Federmann C, Grundkiewicz R, Junczys-Dowmunt M, Mat-\n",
      "sushita H, Menezes A. To ship or not to ship: An extensive eval-\n",
      "uation of automatic metrics for machine translation. arXiv preprint\n",
      "arXiv:210710821. 2021.\n",
      "[71] Freitag M, Rei R, Mathur N, Lo Ck, Stewart C, Avramidis E, et al.\n",
      "Results of WMT22 metrics shared task: Stop using BLEU{neural metrics\n",
      "are better and more robust. In: Proceedings of the Seventh Conference\n",
      "on Machine Translation (WMT); 2022. p. 46-68.\n",
      "[72] Wang J, Liang Y, Meng F, Shi H, Li Z, Xu J, et al. Is chatgpt a good nlg\n",
      "evaluator? a preliminary study. arXiv preprint arXiv:230304048. 2023.\n",
      "32[73] Hermann KM, Kocisky T, Grefenstette E, Espeholt L, Kay W, Suleyman\n",
      "M, et al. Teaching machines to read and comprehend. Advances in neural\n",
      "information processing systems. 2015;28.\n",
      "[74] Zar JH. Spearman rank correlation. Encyclopedia of biostatistics. 2005;7.\n",
      "[75] Mukaka MM. A guide to appropriate use of correlation coe\u000ecient in\n",
      "medical research. Malawi medical journal. 2012;24(3):69-71.\n",
      "[76] Kendall MG. A new measure of rank correlation. Biometrika.\n",
      "1938;30(1/2):81-93.\n",
      "[77] Dai H, Liu Z, Liao W, Huang X, Wu Z, Zhao L, et al. ChatAug: Leveraging\n",
      "ChatGPT for Text Data Augmentation. arXiv preprint arXiv:230213007.\n",
      "2023.\n",
      "[78] Wu C, Yin S, Qi W, Wang X, Tang Z, Duan N. Visual chatgpt: Talk-\n",
      "ing, drawing and editing with visual foundation models. arXiv preprint\n",
      "arXiv:230304671. 2023.\n",
      "[79] Zheng O, Abdel-Aty M, Wang D, Wang Z, Ding S. ChatGPT is on the\n",
      "horizon: Could a large language model be all we need for Intelligent Trans-\n",
      "portation? arXiv preprint arXiv:230305382. 2023.\n",
      "[80] White J, Fu Q, Hays S, Sandborn M, Olea C, Gilbert H, et al. A prompt\n",
      "pattern catalog to enhance prompt engineering with chatgpt. arXiv\n",
      "preprint arXiv:230211382. 2023.\n",
      "[81] Ahmad A, Waseem M, Liang P, Fehmideh M, Aktar MS, Mikkonen T.\n",
      "Towards Human-Bot Collaborative Software Architecting with ChatGPT.\n",
      "arXiv preprint arXiv:230214600. 2023.\n",
      "[82] Lanzi PL, Loiacono D. ChatGPT and Other Large Language Models as\n",
      "Evolutionary Engines for Online Interactive Collaborative Game Design.\n",
      "arXiv preprint arXiv:230302155. 2023.\n",
      "[83] Wang S, Zhao Z, Ouyang X, Wang Q, Shen D. Chatcad: Interactive\n",
      "computer-aided diagnosis on medical image using large language models.\n",
      "arXiv preprint arXiv:230207257. 2023.\n",
      "[84] Hartmann J, Schwenzow J, Witte M. The political ideology of conver-\n",
      "sational AI: Converging evidence on ChatGPT's pro-environmental, left-\n",
      "libertarian orientation. arXiv preprint arXiv:230101768. 2023.\n",
      "[85] Kr ugel S, Ostermaier A, Uhl M. The moral authority of ChatGPT. arXiv\n",
      "preprint arXiv:230107098. 2023.\n",
      "[86] Borji A. A categorical archive of chatgpt failures. arXiv preprint\n",
      "arXiv:230203494. 2023.\n",
      "33[87] Hacker P, Engel A, Mauer M. Regulating chatgpt and other large gener-\n",
      "ative ai models. arXiv preprint arXiv:230202337. 2023.\n",
      "[88] Hacker P. The European AI Liability Directives{Critique of a Half-\n",
      "Hearted Approach and Lessons for the Future. arXiv preprint\n",
      "arXiv:221113960. 2022.\n",
      "[89] Kirk HR, Vidgen B, R ottger P, Hale SA. Personalisation within bounds:\n",
      "A risk taxonomy and policy framework for the alignment of large language\n",
      "models with personalised feedback. arXiv preprint arXiv:230305453. 2023.\n",
      "[90] Bang Y, Cahyawijaya S, Lee N, Dai W, Su D, Wilie B, et al. A multitask,\n",
      "multilingual, multimodal evaluation of chatgpt on reasoning, hallucina-\n",
      "tion, and interactivity. arXiv preprint arXiv:230204023. 2023.\n",
      "[91] Koco\u0013 n J, Cichecki I, Kaszyca O, Kochanek M, Szyd lo D, Baran J,\n",
      "et al. ChatGPT: Jack of all trades, master of none. arXiv preprint\n",
      "arXiv:230210724. 2023.\n",
      "[92] Qin C, Zhang A, Zhang Z, Chen J, Yasunaga M, Yang D. Is chatgpt a\n",
      "general-purpose natural language processing task solver? arXiv preprint\n",
      "arXiv:230206476. 2023.\n",
      "[93] Zhong Q, Ding L, Liu J, Du B, Tao D. Can chatgpt understand too?\n",
      "a comparative study on chatgpt and \fne-tuned bert. arXiv preprint\n",
      "arXiv:230210198. 2023.\n",
      "[94] Zhou C, Qiu C, Acuna DE. Paraphrase Identi\fcation with Deep Learning:\n",
      "A Review of Datasets and Methods. arXiv preprint arXiv:221206933.\n",
      "2022.\n",
      "[95] de Winter J. Can ChatGPT Pass High School Exams on English Language\n",
      "Comprehension? 2023.\n",
      "[96] Yeadon W, Inyang OO, Mizouri A, Peach A, Testrow C. The Death of the\n",
      "Short-Form Physics Essay in the Coming AI Revolution. arXiv preprint\n",
      "arXiv:221211661. 2022.\n",
      "[97] Susnjak T. ChatGPT: The End of Online Exam Integrity? arXiv preprint\n",
      "arXiv:221209292. 2022.\n",
      "[98] Haque MU, Dharmadasa I, Sworna ZT, Rajapakse RN, Ahmad H.\n",
      "\" I think this is the most disruptive technology\": Exploring Senti-\n",
      "ments of ChatGPT Early Adopters using Twitter Data. arXiv preprint\n",
      "arXiv:221205856. 2022.\n",
      "[99] Luan L, Lin X, Li W. Exploring the Cognitive Dynamics of Arti\fcial\n",
      "Intelligence in the Post-COVID-19 and Learning 3.0 Era: A Case Study\n",
      "of ChatGPT. arXiv preprint arXiv:230204818. 2023.\n",
      "34[100] Subhash V. Can Large Language Models Change User Preference Adver-\n",
      "sarially? arXiv preprint arXiv:230210291. 2023.\n",
      "[101] Zhao L, Zhang L, Wu Z, Chen Y, Dai H, Yu X, et al. When Brain-inspired\n",
      "AI Meets AGI. arXiv preprint arXiv:230315935. 2023.\n",
      "[102] Liu Z, Yu X, Zhang L, Wu Z, Cao C, Dai H, et al. DeID-GPT:\n",
      "Zero-shot Medical Text De-Identi\fcation by GPT-4. arXiv preprint\n",
      "arXiv:230311032. 2023.\n",
      "[103] Liu D, Chen Y, Wu Z. Digital Twin (DT)-CycleGAN: Enabling Zero-\n",
      "Shot Sim-to-Real Transfer of Visual Grasping Models. IEEE Robotics\n",
      "and Automation Letters. 2023.\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "print(total_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 청크 사이즈로 자르기\n",
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "            separator=\"\\n\",\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_text(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Summary of ChatGPT/GPT-4 Research\\nand Perspective Towards the Future of Large\\nLanguage Models\\nYiheng Liu\\x031, Tianle Han∗1, Siyuan Ma1, Jiayue Zhang1,\\nYuanyuan Yang1, Jiaming Tian1, Hao He1, Antong Li2, Mengshen\\nHe1, Zhengliang Liu3, Zihao Wu3, Dajiang Zhu4, Xiang Li5, Ning\\nQiang1, Dingang Shen6,7,8, Tianming Liu3, and Bao Ge†1\\n1School of Physics and Information Technology, Shaanxi Normal University, Xi'an\\n710119 China\\n2School of Life and Technology Biomedical-Engineering, Xi'an Jiaotong University,\\nXi'an 710049, China\\n3School of Computing, The University of Georgia, Athens 30602, USA\\n4Department of Computer Science and Engineering, The University of Texas at\\nArlington, Arlington 76019, USA\\n5Department of Radiology, Massachusetts General Hospital and Harvard Medical\\nSchool, Boston 02115, USA\\n6School of Biomedical Engineering, ShanghaiTech University, Shanghai 201210,\\nChina\\n7Shanghai United Imaging Intelligence Co., Ltd., Shanghai 200230, China\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"School, Boston 02115, USA\\n6School of Biomedical Engineering, ShanghaiTech University, Shanghai 201210,\\nChina\\n7Shanghai United Imaging Intelligence Co., Ltd., Shanghai 200230, China\\n8Shanghai Clinical Research and Trial Center, Shanghai 201210, China\\nAbstract\\nThis paper presents a comprehensive survey of ChatGPT and GPT-4,\\nstate-of-the-art large language models (LLM) from the GPT series, and\\ntheir prospective applications across diverse domains. Indeed, key innova-\\ntions such as large-scale pre-training that captures knowledge across the\\nentire world wide web, instruction \\x0cne-tuning and Reinforcement Learn-\\ning from Human Feedback (RLHF) have played signi\\x0ccant roles in en-\\nhancing LLMs' adaptability and performance. We performed an in-depth\\nanalysis of 194 relevant papers on arXiv, encompassing trend analysis,\\nword cloud representation, and distribution analysis across various appli-\\ncation domains. The \\x0cndings reveal a signi\\x0ccant and increasing interest\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 임베딩 /시멘틱 인덱싱하기\n",
    "pip install tiktoken  \n",
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=\"API_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base = FAISS.from_texts(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용자 질문 임베딩하여 시멘틱 Search 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='users to interact with systems, reducing the need for specialized knowledge or\\ntraining. Some studies in the literature we collected have already demonstrated\\nthis.\\nTreude et al. [39] integrated ChatGPT into the prototype of \"GPTCOM-\\nCARE\" to address programming query problems. This integration allowed for\\nthe generation of multiple source code solutions for the same query, which in-\\ncreased the e\\x0eciency of software development. The results of their study demon-\\nstrated the e\\x0bectiveness of using ChatGPT to improve the quality and diversity\\nof code solutions, ultimately reducing the amount of time and e\\x0bort required for\\nsoftware development.Wang et al. [83] proposed the chatCAD method, which\\nutilizes large language models (LLMs) such as ChatGPT to enhance the out-\\nput of multiple CAD networks for medical images, including diagnosis, lesion\\nsegmentation, and report generation networks. The method generates sugges-', metadata={}),\n",
       " Document(page_content=\"tasks. By analyzing the requirements for code generation, ChatGPT can pro-\\nduce code snippets that accurately execute the intended functionality. This not\\nonly saves time and e\\x0bort in writing code from scratch but also reduces the risk\\nof errors that may occur during manual coding. In addition, ChatGPT's ability\\nto learn and adapt to new programming languages and frameworks enables it\\nto complete more complex programming tasks. For example:\\nMegahed et al. [38] discussed the potential of using ChatGPT for tasks\\nsuch as code explanation, suggesting alternative methods for problem-solving\\nwith code, and translating code between programming languages. The solutions\\nprovided by ChatGPT were found to be viable. In another study, Treude et\\nal. [39] introduced a ChatGPT-based prototype called GPTCOMCARE, which\\nhelps programmers generate multiple solutions for a programming problem and\\nhighlight the di\\x0berences between each solution using colors.Sobania et al. [40]\", metadata={}),\n",
       " Document(page_content=\"The results showed that ChatGPT has great potential in generating complex\\ntext output that is not easily captured by plagiarism detection software. The\\nexisting plagiarism detection software should update their plagiarism detection\\nengines. Basic et al. [36] conducted a comparison of the writing performance\\nof students using or not using ChatGPT-3 as a writing aid. The experiment\\nconsisted of two groups of 9 participants each. The control group wrote articles\\nusing traditional methods, while the experimental group used ChatGPT as an\\naid. Two teachers evaluated the papers. The study showed that the assistance of\\nChatGPT did not necessarily improve the quality of the students' essays.Noever\\net al. [37] discusses the potential of using arti\\x0ccial intelligence (AI), particularly\\nlanguage models like GPT (including GPT-3), to create more convincing chat-\\nbots that can deceive humans into thinking they are interacting with another\", metadata={}),\n",
       " Document(page_content='considerations. Through this survey, we hope to provide insights into how these\\nmodels can be improved and extended in the future. In section 2, we will\\nreview the existing work related to ChatGPT, including its applications, ethical\\nconsiderations, and evaluation. In addition to discussing the current state of\\nresearch related to ChatGPT, we will also explore its limitations in section 3.\\nFurthermore, we will provide guidance on future directions for language model\\ndevelopment.\\n2 Related work of ChatGPT\\nIn this section, we review the latest research related to the application, ethics,\\nand evaluation of ChatGPT.\\n2.1 Application of ChatGPT\\n2.1.1 Question And Answering\\nIn the education \\x0celd\\nChatGPT is commonly used for question and answers testing in the edu-\\ncation sector. Users can use ChatGPT to learn, compare and verify answers\\nfor di\\x0berent academic subjects such as physics, mathematics, and chemistry,\\n4Figure 3: The distribution of submitted papers across various \\x0celds.', metadata={})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = knowledge_base.similarity_search(\"where can i use chatGPT\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='users to interact with systems, reducing the need for specialized knowledge or\\ntraining. Some studies in the literature we collected have already demonstrated\\nthis.\\nTreude et al. [39] integrated ChatGPT into the prototype of \"GPTCOM-\\nCARE\" to address programming query problems. This integration allowed for\\nthe generation of multiple source code solutions for the same query, which in-\\ncreased the e\\x0eciency of software development. The results of their study demon-\\nstrated the e\\x0bectiveness of using ChatGPT to improve the quality and diversity\\nof code solutions, ultimately reducing the amount of time and e\\x0bort required for\\nsoftware development.Wang et al. [83] proposed the chatCAD method, which\\nutilizes large language models (LLMs) such as ChatGPT to enhance the out-\\nput of multiple CAD networks for medical images, including diagnosis, lesion\\nsegmentation, and report generation networks. The method generates sugges-', metadata={}),\n",
       "  0.33123994),\n",
       " (Document(page_content=\"tasks. By analyzing the requirements for code generation, ChatGPT can pro-\\nduce code snippets that accurately execute the intended functionality. This not\\nonly saves time and e\\x0bort in writing code from scratch but also reduces the risk\\nof errors that may occur during manual coding. In addition, ChatGPT's ability\\nto learn and adapt to new programming languages and frameworks enables it\\nto complete more complex programming tasks. For example:\\nMegahed et al. [38] discussed the potential of using ChatGPT for tasks\\nsuch as code explanation, suggesting alternative methods for problem-solving\\nwith code, and translating code between programming languages. The solutions\\nprovided by ChatGPT were found to be viable. In another study, Treude et\\nal. [39] introduced a ChatGPT-based prototype called GPTCOMCARE, which\\nhelps programmers generate multiple solutions for a programming problem and\\nhighlight the di\\x0berences between each solution using colors.Sobania et al. [40]\", metadata={}),\n",
       "  0.35184243),\n",
       " (Document(page_content=\"The results showed that ChatGPT has great potential in generating complex\\ntext output that is not easily captured by plagiarism detection software. The\\nexisting plagiarism detection software should update their plagiarism detection\\nengines. Basic et al. [36] conducted a comparison of the writing performance\\nof students using or not using ChatGPT-3 as a writing aid. The experiment\\nconsisted of two groups of 9 participants each. The control group wrote articles\\nusing traditional methods, while the experimental group used ChatGPT as an\\naid. Two teachers evaluated the papers. The study showed that the assistance of\\nChatGPT did not necessarily improve the quality of the students' essays.Noever\\net al. [37] discusses the potential of using arti\\x0ccial intelligence (AI), particularly\\nlanguage models like GPT (including GPT-3), to create more convincing chat-\\nbots that can deceive humans into thinking they are interacting with another\", metadata={}),\n",
       "  0.35378695),\n",
       " (Document(page_content='considerations. Through this survey, we hope to provide insights into how these\\nmodels can be improved and extended in the future. In section 2, we will\\nreview the existing work related to ChatGPT, including its applications, ethical\\nconsiderations, and evaluation. In addition to discussing the current state of\\nresearch related to ChatGPT, we will also explore its limitations in section 3.\\nFurthermore, we will provide guidance on future directions for language model\\ndevelopment.\\n2 Related work of ChatGPT\\nIn this section, we review the latest research related to the application, ethics,\\nand evaluation of ChatGPT.\\n2.1 Application of ChatGPT\\n2.1.1 Question And Answering\\nIn the education \\x0celd\\nChatGPT is commonly used for question and answers testing in the edu-\\ncation sector. Users can use ChatGPT to learn, compare and verify answers\\nfor di\\x0berent academic subjects such as physics, mathematics, and chemistry,\\n4Figure 3: The distribution of submitted papers across various \\x0celds.', metadata={}),\n",
       "  0.35481113)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = knowledge_base.similarity_search_with_score(\"where can i use chatGPT\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT에게 최종 질문하기(load_qa_chain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0,\n",
    "                    openai_api_key=\"API_key\",\n",
    "                    max_tokens=3000,\n",
    "                    model_name='gpt-3.5-turbo',\n",
    "                    request_timeout=120\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChatGPT can be used in various applications, including but not limited to:\\n\\n1. Programming: ChatGPT can assist programmers in generating code snippets, suggesting alternative problem-solving methods, translating code between programming languages, and explaining code.\\n\\n2. Medical Imaging: ChatGPT can enhance the output of CAD networks for medical images, including diagnosis, lesion segmentation, and report generation.\\n\\n3. Writing Aid: ChatGPT can be used as a writing aid to improve writing performance, generate complex text output, and provide assistance in article writing.\\n\\n4. Question and Answering: ChatGPT is commonly used in the education sector for question and answering tasks, allowing users to learn, compare, and verify answers in various academic subjects.\\n\\n5. Chatbots: ChatGPT can be used to create more convincing chatbots that can interact with humans and simulate human-like conversations.\\n\\nThese are just a few examples of the applications of ChatGPT. Its potential is vast, and it can be utilized in various domains where natural language processing and generation are required.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.run(input_documents=docs, question=\"where can i use chatGPT\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT can be used in various applications, including but not limited to:\n",
      "\n",
      "1. Programming: ChatGPT can assist programmers in generating code snippets, suggesting alternative problem-solving methods, translating code between programming languages, and explaining code.\n",
      "\n",
      "2. Medical Imaging: ChatGPT can enhance the output of CAD networks for medical images, including diagnosis, lesion segmentation, and report generation.\n",
      "\n",
      "3. Writing Aid: ChatGPT can be used as a writing aid to improve writing performance, generate complex text output, and provide assistance in article writing.\n",
      "\n",
      "4. Question and Answering: ChatGPT is commonly used in the education sector for question and answering tasks, allowing users to learn, compare, and verify answers in various academic subjects.\n",
      "\n",
      "5. Chatbots: ChatGPT can be used to create more convincing chatbots that can interact with humans and simulate human-like conversations.\n",
      "\n",
      "These are just a few examples of the applications of ChatGPT. Its potential is vast, and it can be utilized in various domains where natural language processing and generation are required.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain을 활용한 또다른 질문방법 RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\langchain\\vectorstores\\chroma.py\", line 80, in __init__\n",
      "    import chromadb\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\chromadb\\__init__.py\", line 4, in <module>\n",
      "    import chromadb.config\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\chromadb\\config.py\", line 12, in <module>\n",
      "    from pydantic import BaseSettings, validator\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\pydantic\\__init__.py\", line 210, in __getattr__\n",
      "    return _getattr_migration(attr_name)\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\pydantic\\_migration.py\", line 289, in wrapper\n",
      "    raise PydanticImportError(\n",
      "pydantic.errors.PydanticImportError: `BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.3/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n",
      "\n",
      "For further information visit https://errors.pydantic.dev/2.3/u/import-error\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Zoon\\AppData\\Local\\Temp\\ipykernel_32792\\4035084074.py\", line 1, in <module>\n",
      "    db = Chroma.from_texts(chunks, embeddings)\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\langchain\\vectorstores\\chroma.py\", line 567, in from_texts\n",
      "    chroma_collection = cls(\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\langchain\\vectorstores\\chroma.py\", line 83, in __init__\n",
      "    raise ImportError(\n",
      "ImportError: Could not import chromadb python package. Please install it with `pip install chromadb`.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\inflearn_chatgpt\\ch10\\ch10_env\\lib\\site-packages\\executing\\executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "db = Chroma.from_texts(chunks, embeddings)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
    "query = \"where can i use chatGPT\"\n",
    "result = qa({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT can be used in various domains and applications. Some examples include:\n",
      "\n",
      "1. Programming: ChatGPT can assist programmers by generating code snippets, suggesting alternative methods for problem-solving, and translating code between programming languages.\n",
      "\n",
      "2. Software Development: ChatGPT can be integrated into software development tools to improve the efficiency and quality of code solutions, reducing the time and effort required for software development.\n",
      "\n",
      "3. Medical Imaging: ChatGPT can enhance the output of CAD networks for medical images, including diagnosis, lesion segmentation, and report generation networks.\n",
      "\n",
      "4. Natural Language Processing: ChatGPT can be used for tasks such as language translation, text summarization, and question-answering systems.\n",
      "\n",
      "5. Customer Support: ChatGPT can be employed in customer support systems to provide automated responses and assist users with their queries.\n",
      "\n",
      "These are just a few examples, and the potential applications of ChatGPT are vast. Its ability to understand and generate human-like text makes it useful in any scenario that requires natural language interaction and assistance.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='users to interact with systems, reducing the need for specialized knowledge or\\ntraining. Some studies in the literature we collected have already demonstrated\\nthis.\\nTreude et al. [39] integrated ChatGPT into the prototype of \"GPTCOM-\\nCARE\" to address programming query problems. This integration allowed for\\nthe generation of multiple source code solutions for the same query, which in-\\ncreased the e\\x0eciency of software development. The results of their study demon-\\nstrated the e\\x0bectiveness of using ChatGPT to improve the quality and diversity\\nof code solutions, ultimately reducing the amount of time and e\\x0bort required for\\nsoftware development.Wang et al. [83] proposed the chatCAD method, which\\nutilizes large language models (LLMs) such as ChatGPT to enhance the out-\\nput of multiple CAD networks for medical images, including diagnosis, lesion\\nsegmentation, and report generation networks. The method generates sugges-', metadata={}), Document(page_content=\"tasks. By analyzing the requirements for code generation, ChatGPT can pro-\\nduce code snippets that accurately execute the intended functionality. This not\\nonly saves time and e\\x0bort in writing code from scratch but also reduces the risk\\nof errors that may occur during manual coding. In addition, ChatGPT's ability\\nto learn and adapt to new programming languages and frameworks enables it\\nto complete more complex programming tasks. For example:\\nMegahed et al. [38] discussed the potential of using ChatGPT for tasks\\nsuch as code explanation, suggesting alternative methods for problem-solving\\nwith code, and translating code between programming languages. The solutions\\nprovided by ChatGPT were found to be viable. In another study, Treude et\\nal. [39] introduced a ChatGPT-based prototype called GPTCOMCARE, which\\nhelps programmers generate multiple solutions for a programming problem and\\nhighlight the di\\x0berences between each solution using colors.Sobania et al. [40]\", metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이전 질문 기록을 포함하여 질분하는 방법 ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a memory object, which is necessary to track the inputs/outputs and hold a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialize the ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m \u001b[39mimport\u001b[39;00m ConversationalRetrievalChain\n\u001b[1;32m----> 2\u001b[0m qa \u001b[39m=\u001b[39m ConversationalRetrievalChain\u001b[39m.\u001b[39mfrom_llm(llm\u001b[39m=\u001b[39mllm, retriever\u001b[39m=\u001b[39mretriever, memory\u001b[39m=\u001b[39mmemory)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "qa = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m chat_history \u001b[39m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwhere can i use chatGPT\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m result \u001b[39m=\u001b[39m qa({\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m: query, \u001b[39m\"\u001b[39m\u001b[39mchat_history\u001b[39m\u001b[39m\"\u001b[39m: chat_history})\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(result[\u001b[39m\"\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qa' is not defined"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"where can i use chatGPT\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#이전 질문 및 답변 저장\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m chat_history \u001b[39m=\u001b[39m [(query, result[\u001b[39m\"\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m\"\u001b[39m])]\n\u001b[0;32m      3\u001b[0m \u001b[39m#다시 질문\u001b[39;00m\n\u001b[0;32m      4\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwhich field is the most used?\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "#이전 질문 및 답변 저장\n",
    "chat_history = [(query, result[\"answer\"])]\n",
    "#다시 질문\n",
    "query = \"which field is the most used?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ch10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
